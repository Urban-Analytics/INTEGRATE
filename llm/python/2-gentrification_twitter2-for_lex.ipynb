{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6e064c-feb0-4b03-bb6d-98b98ea218b1",
   "metadata": {},
   "source": [
    "# (Try to) Extract Gentrification-Relevant Information from public data using a Large Language Model\n",
    "\n",
    "_Adapted version of the script to run a gentrification prediction for some Twitter data that Lex is analysing for an AGILE conference submission_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289af38-0fd0-4823-8189-3e0b1ab90aba",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "e4b1f357-001e-4fc1-bd1c-2061240de22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:17:25.571106Z",
     "start_time": "2025-02-10T17:17:25.567685Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "\n",
    "#from kaggle.api.kaggle_api_extended import KaggleApi  # pip install kaggle\n",
    "from together import Together  # pip install together\n",
    "\n",
    "\n",
    "# Easier display options for debugging: \n",
    "\n",
    "# Set the display width to a larger value\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Optionally, set the max column width to avoid truncating column data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Optionally, set the max number of columns to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Create a log with the current time\n",
    "LOG_FILE = os.path.join(\"logs\", datetime.now().strftime(\"%Y-%m-%d-%H%M%S.log\"))\n",
    "def log(msg):\n",
    "    with open(LOG_FILE, 'a') as f:\n",
    "        f.write(msg)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to get gentrification scores from tweets / etc",
   "id": "dd37f803a9b5c286"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:17:26.973588Z",
     "start_time": "2025-02-10T17:17:26.971869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Default prompt used in the Twitter part\n",
    "_system_prompt = \"\"\"\n",
    "You have a deep understanding of neighbourhood character and how it is experienced discussed in public discourse.\n",
    "I will provide you with some Twitter / X posts (\"tweets\").\n",
    "Your task is to analyse each one text and determine the extent to which each Tweet suggests that the neighbourhood is experiencing change.\n",
    "Specifically:\n",
    "Read the posts closely and identify any words, phrases, or implications that might indicate signs of neighbourhood change, changing demographics, or neighbourhood ‚Äòrevitalisation‚Äô.\n",
    "Consider both explicit and implicit cues. Explicit cues directly mention new businesses or rising prices, while implicit cues might reflect subtle neighbourhood changes.\n",
    "Assign a score from 1 to 5, where 1 means not suggestive of change and 5 means highly suggestive.\n",
    "Do not explain any reasoning.\n",
    "Provide your answer strictly in the format ‚Äò1. Score‚Äô, ‚Äò2. Score‚Äô, ‚Äò3. Score‚Äô, etc., without any additional explanation or commentary.\n",
    "\"\"\""
   ],
   "id": "27d2cf735cdd4708",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:17:27.366349Z",
     "start_time": "2025-02-10T17:17:27.359622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_gentrification_scores(batch_tweets, batch_index=0, system_prompt=_system_prompt, log_file=LOG_FILE, max_tokens=200):\n",
    "    \"\"\"\n",
    "    Retrieves gentrification scores for a batch of tweets using the Together AI API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_tweets : pandas.DataFrame\n",
    "        A DataFrame containing the tweets for the current batch.\n",
    "        It must include a 'text' column with the tweet content.\n",
    "    batch_index : int\n",
    "        An optional starting index of the current batch.\n",
    "        This is used to align the predicted sentiments with the original DataFrame indices.\n",
    "    system_prompt : str\n",
    "        An optional system prompt to be sent to the Together AI API.\n",
    "        The tweet texts will be appended to this prompt.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ids : list of int\n",
    "        A list of DataFrame indices corresponding to each tweet in the batch.\n",
    "        These indices align with the main DataFrame from which this batch was drawn.\n",
    "    sentiments : list of str\n",
    "        A list of predicted gentrification scores for each tweet in the batch.\n",
    "        Possible values are 1 (not suggestive of gentrification) to 5 (highly suggestive).\n",
    "    explanations : list of str\n",
    "        Optional explanations that the LLM returns giving it's reason for the the chosen score\n",
    "        (these may or may not happen depending on the prompt, and the LLM's mood!)\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the list of tweets\n",
    "    tweet_list = \"\\n\".join([f\"{idx + 1}. {tweet}\"\n",
    "                            for idx, tweet in enumerate(batch_tweets.text.values)])\n",
    "\n",
    "    # Create the system prompt\n",
    "    system_prompt = f\"{system_prompt}\\n\\n{tweet_list}\"\n",
    "    #print(\"PROMPT:\", system_prompt, \"\\n\\n\")\n",
    "\n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call the API using parameters that ChatGPT recommends for this task\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "        #model=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,  # max length of output (in case I get the prompt wront and it talks for ages...)\n",
    "        temperature=0.2,  # lower for more deterministic\n",
    "        top_p=0.9,  # ??\n",
    "        top_k=40,  # ??\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "        #truncate=130560,  # ??\n",
    "        stream=False  # Set stream to False to get the full response\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's reply and get the IDs and scores\n",
    "    assistant_reply = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Useful to have a full log for debugging etc\n",
    "    log(f\"{datetime.now().strftime('%Y-%m-%d-%H%M%S')}\\n\" \\\n",
    "        f\"**MESSAGE**\\n{messages}\\n\" \\\n",
    "        f\"**RESPONSE**\\n{assistant_reply}\\n\\n\")\n",
    "\n",
    "    # Parse the IDs and scores (and, if available the explanation for the score)\n",
    "    ids = []\n",
    "    scores = []\n",
    "\n",
    "    # Regex pattern to extract the line number, score, and optional text from a line\n",
    "    #pattern = r'^\\s*(\\d+)\\s*\\.\\s*(\\d+)\\s*$'\n",
    "    #pattern = r'^\\s*(\\d+)\\s*\\.\\s*(\\d+)(?:\\s+(.*))?$'\n",
    "\n",
    "    #pattern = r'''\n",
    "    #    ^\\s*            # Start of the line, allowing for leading whitespace\n",
    "    #    (\\d+)           # Group 1: The line number\n",
    "    #    \\s*[.:]\\s*      # '.' or ':' with optional whitespace on both sides\n",
    "    #    (\\d+)           # Group 2: The score\n",
    "    #    (?:\\s*(.*))?    # Optional text after the score, with optional leading whitespace\n",
    "    #    $               # End of the line\n",
    "    #\n",
    "    #'''\n",
    "    pattern = r'''\n",
    "        ^\\s*              # Start of line, allow leading whitespace\n",
    "        (\\d+)             # Capture Group 1: The line number\n",
    "        \\s*[.:]\\s*        # A dot or colon with optional whitespace\n",
    "        (?:Score:\\s+)?    # Optionally match \"Score:\" followed by one or more spaces\n",
    "        (\\d+)             # Capture Group 2: The score (one or more digits)\n",
    "        (?:\\s*(.*))?      # Optional text after the score (Group 3)\n",
    "        $                 # End of the line\n",
    "    '''\n",
    "\n",
    "    # Desipte being told not to, sometimes the reply starts with 'Here are the scores:'.\n",
    "    # or 'Here are the analyses:'\n",
    "    # Remove at, and any whitespace at the start or end\n",
    "    assistant_reply = re.sub(r'^\\s*Here are the scores:\\s*', '', assistant_reply).strip()\n",
    "    assistant_reply = re.sub(r'^\\s*Here are the analyses:\\s*', '', assistant_reply).strip()\n",
    "\n",
    "    # Analyse the reply line-by-line\n",
    "    lines = assistant_reply.strip().split('\\n')\n",
    "    error_count = 0  # Return -1 on an error (and count the number of errors at the same time)\n",
    "    for i, line in enumerate(lines):\n",
    "        # Ignore lines that are empty once they have been stripped\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Try to match the line\n",
    "        match = re.match(pattern, line, re.VERBOSE)\n",
    "        if match:\n",
    "            # Extract the index and score from the match groups\n",
    "            index = int(match.group(1))\n",
    "            score = int(match.group(2))\n",
    "            log(f\"{i} {line}\\n\\t{index},{score}\")\n",
    "            # Validate the score range\n",
    "            if 1 <= score <= 5:\n",
    "                ids.append(index)\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                msg = f\"Warning: Score {score} out of range on line {i}: '{line}'\"\n",
    "                print(msg)\n",
    "                log(msg)\n",
    "                error_count += 1\n",
    "        else:\n",
    "            msg = f\"\\n*********************\\n\" \\\n",
    "                  f\"Warning: Invalid format on line {i}: '{line}'.\\n\" \\\n",
    "                  f\"The full response was: \\n{assistant_reply}\\n\" \\\n",
    "                  f\"*********************\\n\"\n",
    "            print(msg)\n",
    "            log(msg)\n",
    "            error_count += 1\n",
    "            break\n",
    "\n",
    "        if index-1 >= len(batch_tweets):\n",
    "            msg = f\"Found {index} tweets, but there are more lines. Assuming remaining lines are junk and ignoring them.\"\n",
    "            log(f)\n",
    "            print(f)\n",
    "            break\n",
    "\n",
    "    if error_count > 0:\n",
    "        # There was an error, set scores to -1 and assume tweet IDs from\n",
    "        # 1 to len(batch_tweets).\n",
    "        scores = [-1] * len(batch_tweets)\n",
    "        ids = [x + 1 for x in range(len(batch_tweets))]\n",
    "        # Do I need to also set the indices as the ids array may not have been populated\n",
    "\n",
    "    # Compute dataframe indices\n",
    "    df_ids = [batch_index + int(id) - 1 for id in ids]\n",
    "\n",
    "    #print(\"ids:\", ids)\n",
    "    #print(\"scores:\", scores)\n",
    "\n",
    "    assert len(df_ids) == len(scores), f\"Length of ids ({len(df_ids)} does not match length of scores ({len(scores)}).\"\n",
    "    return df_ids, scores\n",
    "\n",
    "    ## Use regular expressions to extract the scores\n",
    "    #matches = re.findall(r\"(\\d+)\\.\\s*(1|2|3|4|5)\", assistant_reply, re.IGNORECASE)\n",
    "\n",
    "    ## Check that the numbering is correct (optional)\n",
    "    ## You can add code here to verify the numbering matches the tweets\n",
    "\n",
    "    ## Compute the actual DataFrame indices\n",
    "    #ids = [batch_index + int(idx) - 1 for idx, score in matches]\n",
    "    #scores = [int(score) for idx, score in matches]\n",
    "    #assert len(ids) == len(scores)\n",
    "\n",
    "    #return ids, scores\n"
   ],
   "id": "cdb2d50e9e63fdee",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "2fedff62-cb63-42ba-962d-38f7430c5ebc",
   "metadata": {},
   "source": [
    "## Open Twitter data\n",
    "\n",
    "Currently use a historic library of tweets that were downloaded using various APIs by the researchers."
   ]
  },
  {
   "cell_type": "code",
   "id": "dbc91bf5b3c7dcdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:17:28.642758Z",
     "start_time": "2025-02-10T17:17:28.444633Z"
    }
   },
   "source": [
    "tweets_df = pd.read_csv(\n",
    "    os.path.join(\"..\", \"data\", \"uk_tweets\", \"tweets_to_nick.csv.gz\"),\n",
    "    quotechar='\"',\n",
    "    skipinitialspace=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "be091a26-47b7-4c5c-a1d2-5ae5e3b885ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:17:29.748400Z",
     "start_time": "2025-02-10T17:17:29.742937Z"
    }
   },
   "source": [
    "print(tweets_df.columns)\n",
    "tweets_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'tweet_id', 'text', 'lsoa', 'lon', 'lat', 'year', 'month', 'day'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ID             tweet_id                                                                                                                                                                                                                       text       lsoa       lon        lat  year  month  day\n",
       "0          1   549920567307292673                                                                                                                                                                          If I dyed it black nimmy would actually murder me  E01010579 -1.838765  53.858337  2014     12   30\n",
       "1          2   549919548229832705                                                                                                                                                                                            So I miss my black hair already  E01010579 -1.838363  53.858491  2014     12   30\n",
       "2          3   549748079256412160                                                                                                                                                                                  @TomLeach95 sort of is good enough for me  E01010579 -1.838475  53.858450  2014     12   30\n",
       "3          4   549746428806189056                                                                                                                                                                                     @TomLeach95 found him guys don't panic  E01010579 -1.838604  53.858397  2014     12   30\n",
       "4          5   549745180736516096                                                                                                                                                                                                 Where's my Keighley boy at  E01010579 -1.838533  53.858424  2014     12   30\n",
       "...      ...                  ...                                                                                                                                                                                                                        ...        ...       ...        ...   ...    ...  ...\n",
       "92406  92407  1102277364875124736                              How perfect for a casino themed night? Mega QL playing cards with arch for a student ball at Aria Suites. #leedsballoons #casinoballoons #studentnight #playingcards‚Ä¶ https://t.co/7LCNavxarn  E01011668 -1.556857  53.814544  2019      3    3\n",
       "92407  92408  1100050610949443584                                                              Our Butterfly Moments board to encourage meaningful activities and engagement with our residents #happyliving #wellbeing #feelinggood https://t.co/8NQbj5sx2t  E01011668       NaN        NaN  2019      2   25\n",
       "92408  92409  1092163960961404929                                                               ‚ÄúMummy I feel like Cinderella leaving the ball at midnight!‚Äù.......ooops! ‚ù§Ô∏è‚ù§Ô∏è#allinagoodcause #sikhsoldierstatue @ Aria Suite Leeds https://t.co/3i6Jtj3A7s  E01011668 -1.556857  53.814544  2019      2    3\n",
       "92409  92410  1089199016443871232  A Dj always needs a dope host so big up to my broski and comedian Icy Jones aka @Icy_Jones_Comic hosting as I Dj at our friends Pedro and his wife Angel wedding in Leeds\\r\\n...\\r\\nSUBSCRIBE TO‚Ä¶ https://t.co/lnRsnH2M0E  E01011668 -1.556857  53.814544  2019      1   26\n",
       "92410  92411  1083999468343754752                    Wow, how amazing are these light up balloons?! Paired with our mixed confetti/latex tiers, the room looked partified! üòÇ tjsbarleeds #balloons #leedsballoons #birthdayballoons‚Ä¶ https://t.co/dWQYj73r0L  E01011668 -1.556701  53.814476  2019      1   12\n",
       "\n",
       "[92411 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lsoa</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>549920567307292673</td>\n",
       "      <td>If I dyed it black nimmy would actually murder me</td>\n",
       "      <td>E01010579</td>\n",
       "      <td>-1.838765</td>\n",
       "      <td>53.858337</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>549919548229832705</td>\n",
       "      <td>So I miss my black hair already</td>\n",
       "      <td>E01010579</td>\n",
       "      <td>-1.838363</td>\n",
       "      <td>53.858491</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>549748079256412160</td>\n",
       "      <td>@TomLeach95 sort of is good enough for me</td>\n",
       "      <td>E01010579</td>\n",
       "      <td>-1.838475</td>\n",
       "      <td>53.858450</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>549746428806189056</td>\n",
       "      <td>@TomLeach95 found him guys don't panic</td>\n",
       "      <td>E01010579</td>\n",
       "      <td>-1.838604</td>\n",
       "      <td>53.858397</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>549745180736516096</td>\n",
       "      <td>Where's my Keighley boy at</td>\n",
       "      <td>E01010579</td>\n",
       "      <td>-1.838533</td>\n",
       "      <td>53.858424</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92406</th>\n",
       "      <td>92407</td>\n",
       "      <td>1102277364875124736</td>\n",
       "      <td>How perfect for a casino themed night? Mega QL playing cards with arch for a student ball at Aria Suites. #leedsballoons #casinoballoons #studentnight #playingcards‚Ä¶ https://t.co/7LCNavxarn</td>\n",
       "      <td>E01011668</td>\n",
       "      <td>-1.556857</td>\n",
       "      <td>53.814544</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92407</th>\n",
       "      <td>92408</td>\n",
       "      <td>1100050610949443584</td>\n",
       "      <td>Our Butterfly Moments board to encourage meaningful activities and engagement with our residents #happyliving #wellbeing #feelinggood https://t.co/8NQbj5sx2t</td>\n",
       "      <td>E01011668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92408</th>\n",
       "      <td>92409</td>\n",
       "      <td>1092163960961404929</td>\n",
       "      <td>‚ÄúMummy I feel like Cinderella leaving the ball at midnight!‚Äù.......ooops! ‚ù§Ô∏è‚ù§Ô∏è#allinagoodcause #sikhsoldierstatue @ Aria Suite Leeds https://t.co/3i6Jtj3A7s</td>\n",
       "      <td>E01011668</td>\n",
       "      <td>-1.556857</td>\n",
       "      <td>53.814544</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92409</th>\n",
       "      <td>92410</td>\n",
       "      <td>1089199016443871232</td>\n",
       "      <td>A Dj always needs a dope host so big up to my broski and comedian Icy Jones aka @Icy_Jones_Comic hosting as I Dj at our friends Pedro and his wife Angel wedding in Leeds\\r\\n...\\r\\nSUBSCRIBE TO‚Ä¶ https://t.co/lnRsnH2M0E</td>\n",
       "      <td>E01011668</td>\n",
       "      <td>-1.556857</td>\n",
       "      <td>53.814544</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92410</th>\n",
       "      <td>92411</td>\n",
       "      <td>1083999468343754752</td>\n",
       "      <td>Wow, how amazing are these light up balloons?! Paired with our mixed confetti/latex tiers, the room looked partified! üòÇ tjsbarleeds #balloons #leedsballoons #birthdayballoons‚Ä¶ https://t.co/dWQYj73r0L</td>\n",
       "      <td>E01011668</td>\n",
       "      <td>-1.556701</td>\n",
       "      <td>53.814476</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92411 rows √ó 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "47c5b212a4c05d4",
   "metadata": {},
   "source": "## Use the Together.AI API to batch classify the Tweets as how likely they are to be related to gentrification."
  },
  {
   "cell_type": "markdown",
   "id": "ed80e2d44ed95f5b",
   "metadata": {},
   "source": [
    "A function that takes a batch of tweets and uses the Together API to classify them. The `_system_prompt` variable contains the prompt that will be sent to the API; individual tweets are appended to this.\n",
    "\n",
    "The LLM requires some parameter values. Here are the settings that chatGPT recommended (with defaults, that I decided not to use, in brackets)\n",
    "\n",
    "1.\tmax_tokens:\n",
    "\t-\tRecommendation: 50 (200)\n",
    "\t-\tExplanation: Since you‚Äôre expecting short responses like '1. Score', a small max_tokens value ensures concise outputs without unnecessary verbosity.\n",
    "\t-    _(I actually choose a larger value because the prompt has been designed to get the LLM to stop long before max_tokens is reached and this way it is hopefully less likely to break if we increase the batch size.\n",
    "2.\ttemperature:\n",
    "\t-\tRecommendation: 0.2 (0.7)\n",
    "\t-\tExplanation: A lower temperature makes the model‚Äôs output more deterministic, which is ideal for scoring tasks where consistency is important.\n",
    "3.\ttop_p:\n",
    "\t-\tRecommendation: 0.9 (0.7)\n",
    "\t-\tExplanation: This value balances the randomness and coherence of the output by considering tokens with a cumulative probability up to 90%.\n",
    "4.\ttop_k:\n",
    "\t-\tRecommendation: 40 (50)\n",
    "\t-\tExplanation: Limits the model to consider the top 40 probable next tokens, which helps in generating relevant responses.\n",
    "5.\trepetition_penalty:\n",
    "\t-\tRecommendation: 1.1 (1)\n",
    "\t-\tExplanation: Slightly penalizes repeated tokens to prevent the model from producing redundant information."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note**: The cell below needs updating now that the `get_gentrification_scores` fuction returns the prediction as well as it's score (used later). This means the twitter LLM prompt may need updating too (or maybe not if the regex that parses the LLM output is flexible enough) but I can't be bothered to go back and fix this as this work is redundant now anyway (moving on from this twitter test).",
   "id": "e5fb43af611d0971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the API key from a file\n",
    "with open('together.ai_key.txt', 'r') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "# List of tweets to classify (can sample if I want to)\n",
    "#df = tweets_df.sample(200).copy()\n",
    "df = tweets_df.copy()\n",
    "\n",
    "print(f\"Will query the LM for {len(df)} tweets\")\n",
    "\n",
    "#assert len(df) < 1000, \"Too many tweets to process in one go. Please reduce the number of tweets.\"\n",
    "\n",
    "# Ensure the index is consecutive and ascending\n",
    "df = df.reset_index(drop=True)\n",
    "# To store the results\n",
    "df['gentrification_prediction'] = None\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 20\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Get the batch of tweets\n",
    "    batch_tweets = df.loc[i:i + batch_size - 1, :]\n",
    "\n",
    "    # Get sentiments using the function\n",
    "    print(f\"Submitting batch {i//len(batch_tweets)+1} of {len(df)//len(batch_tweets)}...\")\n",
    "\n",
    "    ids, sentiments = get_gentrification_scores(batch_tweets, batch_index=i)\n",
    "\n",
    "    #for idx, score in zip(ids, sentiments):\n",
    "    #    print(f\"\\t{idx}: {score}\")\n",
    "\n",
    "    # Update the DataFrame with the predictions\n",
    "    df.loc[ids, 'gentrification_prediction'] = sentiments\n",
    "\n",
    "print(\"Finished\")"
   ],
   "id": "c4c34f4ac7c279c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6718b2ff0eaaf7b",
   "metadata": {},
   "source": [
    "See how well that worked"
   ]
  },
  {
   "cell_type": "code",
   "id": "65d426a618b7e3c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:31:36.936406Z",
     "start_time": "2025-02-10T19:31:36.929063Z"
    }
   },
   "source": "df.loc[:,['text', 'gentrification_prediction']]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                            text gentrification_prediction\n",
       "0                                                                                                                                                                              If I dyed it black nimmy would actually murder me                         1\n",
       "1                                                                                                                                                                                                So I miss my black hair already                         1\n",
       "2                                                                                                                                                                                      @TomLeach95 sort of is good enough for me                         1\n",
       "3                                                                                                                                                                                         @TomLeach95 found him guys don't panic                         1\n",
       "4                                                                                                                                                                                                     Where's my Keighley boy at                         1\n",
       "...                                                                                                                                                                                                                          ...                       ...\n",
       "92406                              How perfect for a casino themed night? Mega QL playing cards with arch for a student ball at Aria Suites. #leedsballoons #casinoballoons #studentnight #playingcards‚Ä¶ https://t.co/7LCNavxarn                         2\n",
       "92407                                                              Our Butterfly Moments board to encourage meaningful activities and engagement with our residents #happyliving #wellbeing #feelinggood https://t.co/8NQbj5sx2t                         1\n",
       "92408                                                               ‚ÄúMummy I feel like Cinderella leaving the ball at midnight!‚Äù.......ooops! ‚ù§Ô∏è‚ù§Ô∏è#allinagoodcause #sikhsoldierstatue @ Aria Suite Leeds https://t.co/3i6Jtj3A7s                         2\n",
       "92409  A Dj always needs a dope host so big up to my broski and comedian Icy Jones aka @Icy_Jones_Comic hosting as I Dj at our friends Pedro and his wife Angel wedding in Leeds\\r\\n...\\r\\nSUBSCRIBE TO‚Ä¶ https://t.co/lnRsnH2M0E                         2\n",
       "92410                    Wow, how amazing are these light up balloons?! Paired with our mixed confetti/latex tiers, the room looked partified! üòÇ tjsbarleeds #balloons #leedsballoons #birthdayballoons‚Ä¶ https://t.co/dWQYj73r0L                         2\n",
       "\n",
       "[92411 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gentrification_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If I dyed it black nimmy would actually murder me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So I miss my black hair already</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TomLeach95 sort of is good enough for me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@TomLeach95 found him guys don't panic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's my Keighley boy at</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92406</th>\n",
       "      <td>How perfect for a casino themed night? Mega QL playing cards with arch for a student ball at Aria Suites. #leedsballoons #casinoballoons #studentnight #playingcards‚Ä¶ https://t.co/7LCNavxarn</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92407</th>\n",
       "      <td>Our Butterfly Moments board to encourage meaningful activities and engagement with our residents #happyliving #wellbeing #feelinggood https://t.co/8NQbj5sx2t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92408</th>\n",
       "      <td>‚ÄúMummy I feel like Cinderella leaving the ball at midnight!‚Äù.......ooops! ‚ù§Ô∏è‚ù§Ô∏è#allinagoodcause #sikhsoldierstatue @ Aria Suite Leeds https://t.co/3i6Jtj3A7s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92409</th>\n",
       "      <td>A Dj always needs a dope host so big up to my broski and comedian Icy Jones aka @Icy_Jones_Comic hosting as I Dj at our friends Pedro and his wife Angel wedding in Leeds\\r\\n...\\r\\nSUBSCRIBE TO‚Ä¶ https://t.co/lnRsnH2M0E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92410</th>\n",
       "      <td>Wow, how amazing are these light up balloons?! Paired with our mixed confetti/latex tiers, the room looked partified! üòÇ tjsbarleeds #balloons #leedsballoons #birthdayballoons‚Ä¶ https://t.co/dWQYj73r0L</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92411 rows √ó 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:32:42.210567Z",
     "start_time": "2025-02-10T19:32:41.902725Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"./lex_tweets_genrification.csv\")",
   "id": "3c14ce236811d258",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:34:16.794650Z",
     "start_time": "2025-02-10T19:34:16.789841Z"
    }
   },
   "cell_type": "code",
   "source": "df.gentrification_prediction.value_counts()",
   "id": "eeebfccebcb9bfa3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gentrification_prediction\n",
       "1    82052\n",
       "2     5909\n",
       "3     2052\n",
       "4     2036\n",
       "5      362\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
