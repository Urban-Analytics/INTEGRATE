{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb2add0",
   "metadata": {},
   "source": [
    "## FindMeanEmbeddings_ForEachOf7Clusters\n",
    "This script:\n",
    "- Reads in a pickle files which contains a dataframe with one row per sampled image. Each image is associated with a location (lat, lon), a link to the image_file, an embedding, category_scores, and the cluster the image has been assigned to with cluster numbers between 2 and 10 \n",
    "- Finds the percentage of images in each LSOA, within each of the clusters\n",
    "- Finds the mean/min/max embedding within each cluster, within each LSOA\n",
    "- Saves a pickle file containing a dataframe containing this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8cf3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def is_missing_embedding(x):\n",
    "    return isinstance(x, float) and np.isnan(x)\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f89e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"../../../../data/embeddings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de01581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2331d9",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e3b8511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_data_cache = data_dir + f\"embeddings/one_row_per_image_cleaned_with_cluster_numbers.pkl\"\n",
    "with open(points_data_cache, \"rb\") as f:\n",
    "    expanded_gdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa823737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10758\n",
      "2\n",
      "12799\n",
      "3\n",
      "15354\n",
      "4\n",
      "13970\n",
      "5\n",
      "7517\n",
      "6\n",
      "7150\n",
      "7\n",
      "7928\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,8):\n",
    "    print(num)\n",
    "    print(len(expanded_gdf[expanded_gdf['scene_cluster_7']==num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fadaf",
   "metadata": {},
   "source": [
    "# Create a dataframe with % of images in each category, in each LSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4018ba04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_images</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>pct_1</th>\n",
       "      <th>pct_2</th>\n",
       "      <th>pct_3</th>\n",
       "      <th>pct_4</th>\n",
       "      <th>pct_5</th>\n",
       "      <th>pct_6</th>\n",
       "      <th>pct_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA21CD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E01004766</th>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>21.875</td>\n",
       "      <td>9.375000</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>15.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004767</th>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.722222</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>18.055556</td>\n",
       "      <td>12.500</td>\n",
       "      <td>18.055556</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>18.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004768</th>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.090909</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004769</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004770</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>12.500</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           total_images  count_1  count_2  count_3  count_4  count_5  count_6  \\\n",
       "LSOA21CD                                                                        \n",
       "E01004766            64      8.0     10.0     13.0     14.0      6.0      3.0   \n",
       "E01004767            72      7.0     12.0     13.0      9.0     13.0      5.0   \n",
       "E01004768            44      0.0     15.0     14.0      0.0      5.0      9.0   \n",
       "E01004769            40      1.0     10.0      9.0      1.0      9.0      9.0   \n",
       "E01004770            40      1.0     11.0     12.0      5.0      5.0      5.0   \n",
       "\n",
       "           count_7      pct_1      pct_2      pct_3   pct_4      pct_5  \\\n",
       "LSOA21CD                                                                 \n",
       "E01004766     10.0  12.500000  15.625000  20.312500  21.875   9.375000   \n",
       "E01004767     13.0   9.722222  16.666667  18.055556  12.500  18.055556   \n",
       "E01004768      1.0   0.000000  34.090909  31.818182   0.000  11.363636   \n",
       "E01004769      1.0   2.500000  25.000000  22.500000   2.500  22.500000   \n",
       "E01004770      1.0   2.500000  27.500000  30.000000  12.500  12.500000   \n",
       "\n",
       "               pct_6      pct_7  \n",
       "LSOA21CD                         \n",
       "E01004766   4.687500  15.625000  \n",
       "E01004767   6.944444  18.055556  \n",
       "E01004768  20.454545   2.272727  \n",
       "E01004769  22.500000   2.500000  \n",
       "E01004770  12.500000   2.500000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = expanded_gdf\n",
    "category_column = f\"scene_cluster_{k}\"\n",
    "\n",
    "# --- 1. Count images per (LSOA, category) ---\n",
    "category_counts = (df.groupby([\"LSOA21CD\", category_column]).size().reset_index(name=\"count\"))\n",
    "\n",
    "# --- 2. Total images per LSOA ---\n",
    "total_counts = (df.groupby(\"LSOA21CD\").size().reset_index(name=\"total_images\"))\n",
    "\n",
    "# --- 3. Merge totals ---\n",
    "category_counts = category_counts.merge(total_counts, on=\"LSOA21CD\")\n",
    "\n",
    "# --- 4. Add percentage for each category ---\n",
    "category_counts[\"pct\"] = (category_counts[\"count\"] / category_counts[\"total_images\"] * 100)\n",
    "\n",
    "# --- 5. Wide table: counts in columns ---\n",
    "counts_wide = (category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"count\").fillna(0).add_prefix(\"count_\"))\n",
    "\n",
    "# --- 6. Wide table: percentages in columns ---\n",
    "pct_wide = (category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"pct\")\n",
    "        .fillna(0).add_prefix(\"pct_\"))\n",
    "\n",
    "# --- 7. Combine both + total images per LSOA ---\n",
    "lsoa_summary = (total_counts.set_index(\"LSOA21CD\").join([counts_wide, pct_wide]))\n",
    "\n",
    "# plt.hist(lsoa_summary['total_images'], bins=20)\n",
    "\n",
    "lsoa_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48673ab",
   "metadata": {},
   "source": [
    "# Find mean/median/max embedding in each LSOA, also by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64c11071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aggregation functions\n",
    "def mean_embed(series):\n",
    "    return np.mean(np.stack(series.values), axis=0)\n",
    "\n",
    "def max_embed(series):\n",
    "    return np.max(np.stack(series.values), axis=0)\n",
    "\n",
    "def median_embed(series):\n",
    "    return np.median(np.stack(series.values), axis=0)\n",
    "\n",
    "agg_funcs = {\"mean\": mean_embed, \"max\": max_embed, \"median\": median_embed}\n",
    "\n",
    "# List of categories\n",
    "categories = df[category_column].unique()\n",
    "\n",
    "# Initialize list to hold all DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "for agg_name, func in agg_funcs.items():\n",
    "    dfs = []\n",
    "    \n",
    "    # Per-category embeddings\n",
    "    for cat in categories:\n",
    "        df_cat = df[df[category_column] == cat]\n",
    "        emb_cat = df_cat.groupby(\"LSOA21CD\")[\"embedding\"].apply(func).reset_index()\n",
    "        emb_cat = emb_cat.rename(columns={\"embedding\": f\"{cat}_{agg_name}\"})\n",
    "        dfs.append(emb_cat)\n",
    "    \n",
    "    # Merge all categories\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), dfs)\n",
    "    \n",
    "    # Overall embedding (all images in LSOA)\n",
    "    overall = expanded_gdf.groupby(\"LSOA21CD\")[\"embedding\"].apply(func).reset_index()\n",
    "    overall = overall.rename(columns={\"embedding\": f\"overall_{agg_name}\"})\n",
    "    \n",
    "    merged = merged.merge(overall, on=\"LSOA21CD\", how=\"left\")\n",
    "    \n",
    "    all_dfs.append(merged)\n",
    "\n",
    "# Merge mean, max, median into a single DataFrame\n",
    "final_df = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), all_dfs)\n",
    "\n",
    "# # Fill missing embeddings with zeros if needed\n",
    "# final_df = final_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cb64a",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad218412",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(lsoa_summary, on = \"LSOA21CD\")\n",
    "final_df.to_pickle(data_dir + f\"per_lsoa_embedding_summaries/mean_embedding_per_cluster.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e67a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10758.0\n",
      "12799.0\n"
     ]
    }
   ],
   "source": [
    "print(final_df['count_1'].sum())\n",
    "print(final_df['count_2'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
