{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb2add0",
   "metadata": {},
   "source": "## FindMedianEmbeddings_ForEachOf7Clusters\nThis script:\n- Reads the expanded dataframe (one row per image) with cluster assignments (output of script 5)\n- For a chosen k, computes per-LSOA summary statistics:\n    - Count and percentage of images in each cluster\n    - Mean, max, and median embedding within each cluster\n    - Overall mean, max, and median embedding (across all clusters)\n- Saves a single pickle file combining all of the above"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cf3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "import os\nimport numpy as np\nimport pandas as pd\nfrom functools import reduce"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f89e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from directory_filepaths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de01581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2331d9",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b8511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Load expanded dataframe with cluster assignments (output of script 5)\nexpanded_gdf = pd.read_pickle(os.path.join(data_dir, \"one_row_per_image_cleaned_with_cluster_numbers.pkl\"))\nprint(f\"Loaded {len(expanded_gdf)} image rows\")"
  },
  {
   "cell_type": "markdown",
   "id": "d40fadaf",
   "metadata": {},
   "source": [
    "# Create a dataframe with % of images in each category, in each LSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018ba04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "category_column = f\"scene_cluster_{k}\"\n\n# Count images per (LSOA, cluster)\ncategory_counts = (\n    expanded_gdf.groupby([\"LSOA21CD\", category_column])\n    .size()\n    .reset_index(name=\"count\")\n)\n\n# Total images per LSOA\ntotal_counts = expanded_gdf.groupby(\"LSOA21CD\").size().reset_index(name=\"total_images\")\n\n# Merge and compute percentages\ncategory_counts = category_counts.merge(total_counts, on=\"LSOA21CD\")\ncategory_counts[\"pct\"] = category_counts[\"count\"] / category_counts[\"total_images\"] * 100\n\n# Pivot to wide format: one column per cluster for counts and percentages\ncounts_wide = (\n    category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"count\")\n    .fillna(0)\n    .add_prefix(\"count_\")\n)\npct_wide = (\n    category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"pct\")\n    .fillna(0)\n    .add_prefix(\"pct_\")\n)\n\n# Combine counts, percentages, and totals per LSOA\nlsoa_summary = total_counts.set_index(\"LSOA21CD\").join([counts_wide, pct_wide])\n\nlsoa_summary.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c48673ab",
   "metadata": {},
   "source": [
    "# Find mean/median/max embedding in each LSOA, also by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c11071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "def mean_embed(series):\n    return np.mean(np.stack(series.values), axis=0)\n\ndef max_embed(series):\n    return np.max(np.stack(series.values), axis=0)\n\ndef median_embed(series):\n    return np.median(np.stack(series.values), axis=0)\n\nagg_funcs = {\"mean\": mean_embed, \"max\": max_embed, \"median\": median_embed}\ncategories = sorted(expanded_gdf[category_column].unique())\n\nall_dfs = []\n\nfor agg_name, func in agg_funcs.items():\n    dfs = []\n\n    # Per-cluster embedding aggregation\n    for cat in categories:\n        emb_cat = (\n            expanded_gdf[expanded_gdf[category_column] == cat]\n            .groupby(\"LSOA21CD\")[\"embedding\"]\n            .apply(func)\n            .reset_index()\n            .rename(columns={\"embedding\": f\"{cat}_{agg_name}\"})\n        )\n        dfs.append(emb_cat)\n\n    # Merge all clusters, then add overall (all images in LSOA)\n    merged = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), dfs)\n\n    overall = (\n        expanded_gdf.groupby(\"LSOA21CD\")[\"embedding\"]\n        .apply(func)\n        .reset_index()\n        .rename(columns={\"embedding\": f\"overall_{agg_name}\"})\n    )\n    merged = merged.merge(overall, on=\"LSOA21CD\", how=\"left\")\n    all_dfs.append(merged)\n\n# Combine mean, max, and median into a single DataFrame\nfinal_df = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), all_dfs)\nprint(f\"{len(final_df)} LSOAs, {len(final_df.columns) - 1} feature columns\")"
  },
  {
   "cell_type": "markdown",
   "id": "df2cb64a",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad218412",
   "metadata": {},
   "outputs": [],
   "source": "# Attach the LSOA count/percentage summary and save\nfinal_df = final_df.merge(lsoa_summary, on=\"LSOA21CD\")\n\noutput_path = os.path.join(data_dir, \"per_lsoa_embedding_summaries\", \"median_embedding_per_cluster.pkl\")\nos.makedirs(os.path.dirname(output_path), exist_ok=True)\nfinal_df.to_pickle(output_path)\nprint(f\"Saved to {output_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e67a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6063.0\n",
      "17571.0\n"
     ]
    }
   ],
   "source": [
    "print(final_df['count_1'].sum())\n",
    "print(final_df['count_2'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}