{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3380d8e2",
   "metadata": {},
   "source": [
    "## IdentifyEmbeddingGroupings\n",
    "This script:\n",
    "- Loads the pickle file containing each sample point, the list of image files, the list of embeddings and the list of similarity scores\n",
    "- Converts it so that each image (and associated embedding/scores) is its own row\n",
    "- Removes some outlying images:\n",
    "    - This stage may not be necessary, but does effectively remove images of both inside of buildings and inside of cars.\n",
    "    - This is based on using UMAP to reduce the dimensionality of embeddings to 2, and then plotting in 2-dimensional space.\n",
    "    There are two very clearly separated clusters of points which when I looked at the images within them, were those inside the cars and inside the buildings\n",
    "- Cluster analysis:\n",
    "    - Test whether there is a structure within the embeddings that would allow them to be broken down into sub-clusters\n",
    "        - Silhouette scores (are scores higher than 1?)\n",
    "        - Elbow scores\n",
    "        - Adjusted Rand Index\n",
    "    - Decide on the optimal K\n",
    "    - Run a K-mean cluster analysis with optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8cf3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "import umap\n",
    "import random\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f89e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"../../../../data/embeddings/\")\n",
    "lsoas_file = os.path.join(\"../../../../data/SpatialData/\", \"LSOAs_2021\", \"LSOA_2021_EW_BSC_V4.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a64fe",
   "metadata": {},
   "source": [
    "### Get spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8395946f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsoas =  gpd.read_file(lsoas_file)\n",
    "manc_lads = ['Manchester', 'Rochdale', 'Bolton', 'Bury', 'Wigan', 'Oldham',  'Trafford', 'Salford', 'Tameside', 'Stockport']\n",
    "manc_lads_pattern = '|'.join(manc_lads)\n",
    "gm_lsoa=lsoas[lsoas['LSOA21NM'].str.contains(manc_lads_pattern)]\n",
    "gm_lsoa = gm_lsoa.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2331d9",
   "metadata": {},
   "source": [
    "### Get embeddings (four per location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3b8511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_data_cache = data_dir + f\"sample_points_cache/points_data_cache_with_CLIP_embeddings_and_scores_planninguseclasses.pkl\"\n",
    "with open(points_data_cache, \"rb\") as f:\n",
    "    point_records = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4899715",
   "metadata": {},
   "source": [
    "### Join image embeddings points to gentrification LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af05acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points after spatial join: 18897 / 18897 `(some points may lie outside the label polygons and were dropped)\n"
     ]
    }
   ],
   "source": [
    "point_coords = [Point(rec['longitude'], rec['latitude']) for rec in point_records]\n",
    "points_labels_gdf = gpd.GeoDataFrame(point_records, geometry=point_coords, crs=\"EPSG:4326\")\n",
    "\n",
    "# Perform spatial join to get gentrification label for each point\n",
    "points_labels_gdf = gpd.sjoin(points_labels_gdf, gm_lsoa, how='inner', predicate='within')\n",
    "\n",
    "# sjoin may add an index from the polygon ('index_right'); we can drop it\n",
    "if 'index_right' in points_labels_gdf.columns:\n",
    "    points_labels_gdf = points_labels_gdf.drop(columns=['index_right'])\n",
    "\n",
    "print(f\"Points after spatial join: {len(points_labels_gdf)} / {len(point_records)}\"\n",
    "      f\" `(some points may lie outside the label polygons and were dropped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63915949",
   "metadata": {},
   "source": [
    "# Expand dataframe so there is one row per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5c82ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row 9158: 3 embedding, 4 images\n",
      "Skipping row 18664: 3 embedding, 4 images\n",
      "Original rows: 18897, Expanded rows: 75580\n"
     ]
    }
   ],
   "source": [
    "expanded_rows = []\n",
    "\n",
    "for _, row in points_labels_gdf.iterrows():\n",
    "    embeddings = row['embedding']      # list of 4 embeddings\n",
    "    images = row['image_files']        # list of 4 image paths\n",
    "    cat_scores = row['category_scores']        # list of 4 image paths\n",
    "    \n",
    "    # Skip if lengths don't match\n",
    "    if len(embeddings) != len(images):\n",
    "        print(f\"Skipping row {row.name}: {len(embeddings)} embedding, {len(images)} images\")\n",
    "        continue\n",
    "\n",
    "    for score, emb, img in zip(cat_scores, embeddings, images):\n",
    "        new_row = row.to_dict()        # copy all other columns\n",
    "        new_row['embedding'] = emb     # single embedding\n",
    "        new_row['image_files'] = img    # single image\n",
    "        new_row['category_scores'] = score\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "# Create new DataFrame\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)\n",
    "print(f\"Original rows: {len(points_labels_gdf)}, Expanded rows: {len(expanded_gdf)}\")\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65b2f7",
   "metadata": {},
   "source": [
    "# Remove inside cars and inside buildings images\n",
    "This stage is potentially not necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c25d1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Example wrapper if you have a dataframe\n",
    "# embeddings = np.vstack(expanded_gdf[\"embedding\"].values)   # shape (N, 512)\n",
    "#              # string labels\n",
    "# reducer = umap.UMAP(\n",
    "#     n_neighbors=30, \n",
    "#     min_dist=0.1, \n",
    "#     metric='cosine',   # ✔ recommended for CLIP embeddings\n",
    "#     random_state=42)\n",
    "\n",
    "# emb_2d = reducer.fit_transform(embeddings)  # shape (N, 2)\n",
    "\n",
    "# expanded_gdf['umap_x'] = emb_2d[:, 0]\n",
    "# expanded_gdf['umap_y'] = emb_2d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826ea893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------\n",
    "# # 2. Define MULTIPLE bounding boxes\n",
    "# #    Format: (x_min, x_max, y_min, y_max)\n",
    "# # ---------------------------------------------------------\n",
    "# bounding_boxes = [(5.7, 6.3, 9.5, 10),     # Box 1\n",
    "#                   (2.3, 3.2, 8.5,9)]\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 3. Build mask for ANY point inside ANY box\n",
    "# # ---------------------------------------------------------\n",
    "# inside_any_box = np.zeros(len(expanded_gdf), dtype=bool)\n",
    "\n",
    "# for (x_min, x_max, y_min, y_max) in bounding_boxes:\n",
    "#     inside_this_box = (\n",
    "#         (expanded_gdf[\"umap_x\"] >= x_min) & (expanded_gdf[\"umap_x\"] <= x_max) &\n",
    "#         (expanded_gdf[\"umap_y\"] >= y_min) & (expanded_gdf[\"umap_y\"] <= y_max))\n",
    "#     inside_any_box |= inside_this_box      # combine masks\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 4. Remove all points inside any bounding box\n",
    "# # ---------------------------------------------------------\n",
    "# expanded_gdf_filtered = expanded_gdf[~inside_any_box].copy()\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 5. Visual sanity check\n",
    "# # ---------------------------------------------------------\n",
    "# plt.figure(figsize=(4, 3))\n",
    "\n",
    "# # Points kept\n",
    "# plt.scatter(expanded_gdf_filtered[\"umap_x\"], expanded_gdf_filtered[\"umap_y\"], s=2, alpha=0.25, label=\"kept\")\n",
    "\n",
    "# # Points removed\n",
    "# plt.scatter(expanded_gdf.loc[inside_any_box, \"umap_x\"], expanded_gdf.loc[inside_any_box, \"umap_y\"], s=10, color=\"red\",\n",
    "#             label=\"removed\")\n",
    "\n",
    "# # Draw rectangles on the plot\n",
    "# ax = plt.gca()\n",
    "# for (x_min, x_max, y_min, y_max) in bounding_boxes:\n",
    "#     rect = plt.Rectangle((x_min, y_min),x_max - x_min,y_max - y_min,linewidth=2,edgecolor=\"black\", facecolor=\"none\")\n",
    "#     ax.add_patch(rect)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title(\"UMAP with Multiple Removed Bounding Boxes\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # (Optional) overwrite original:\n",
    "# expanded_gdf = expanded_gdf_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4edad",
   "metadata": {},
   "source": [
    "# Run cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609944d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.stack(expanded_gdf['embedding'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686af6f",
   "metadata": {},
   "source": [
    "### Examine silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb9941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_k, inertias, sil_scores = find_optimal_k_fast(all_embeddings)\n",
    "# print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa4f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Silhouette Score: 0.13796169\n",
      "3: Silhouette Score: 0.049932152\n",
      "4: Silhouette Score: 0.051864285\n",
      "5: Silhouette Score: 0.052126907\n",
      "6: Silhouette Score: 0.045081306\n",
      "7: Silhouette Score: 0.041515075\n",
      "8: Silhouette Score: 0.03392916\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2,20):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(all_embeddings)\n",
    "    silhouette_avg = silhouette_score(all_embeddings, labels)\n",
    "    print(f\"{n_clusters}: Silhouette Score:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1e8c7",
   "metadata": {},
   "source": [
    "### Examine elbow scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1223b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k, ks, inertias = find_optimal_k_elbow(all_embeddings)\n",
    "plot_elbow(ks, inertias, optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac719d8",
   "metadata": {},
   "source": [
    "### Assess clustering stability using the adjusted rand index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e41888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_stability(all_embeddings, k, n_runs=10):\n",
    "    \"\"\"\n",
    "    Run k-means multiple times with different random initialisations\n",
    "    and compute pairwise Adjusted Rand Index (ARI).\n",
    "    \"\"\"\n",
    "    labels_list = []\n",
    "\n",
    "    for seed in range(n_runs):\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=k,\n",
    "            n_init=1,          # important: single init per run\n",
    "            random_state=seed\n",
    "        )\n",
    "        labels = kmeans.fit_predict(all_embeddings)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # Compute pairwise ARI\n",
    "    ari_scores = []\n",
    "    for i in range(len(labels_list)):\n",
    "        for j in range(i + 1, len(labels_list)):\n",
    "            ari = adjusted_rand_score(labels_list[i], labels_list[j])\n",
    "            ari_scores.append(ari)\n",
    "\n",
    "    return np.mean(ari_scores), np.std(ari_scores), ari_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83580b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,10):\n",
    "    mean_ari, std_ari, _ = clustering_stability(all_embeddings, k)\n",
    "    print(f\"k={k}: ARI = {mean_ari:.2f} ± {std_ari:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb943ad6",
   "metadata": {},
   "source": [
    "### Run with optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4cbd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in [2,7]:\n",
    "    print(k)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(all_embeddings)\n",
    "    expanded_gdf[f'scene_cluster_{k}'] = labels + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b5fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.unique(expanded_gdf[f\"scene_cluster_{k}\"],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949271d",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_gdf.to_pickle(data_dir + f\"embedding_summaries/expanded_gdf_withclustering.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76702200",
   "metadata": {},
   "source": [
    "### Check the images in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7122568",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total_k = 7\n",
    "\n",
    "# for this_cluster_num in range(1,total_k+1):\n",
    "\n",
    "#     umap_df = pd.DataFrame({\n",
    "#         \"x\": emb_2d[:, 0],\n",
    "#         \"y\": emb_2d[:, 1],\n",
    "#         \"image_id\": expanded_gdf[\"point_id\"],\n",
    "#         \"image_files\": expanded_gdf[\"image_files\"],\n",
    "#          \"cluster_id\": expanded_gdf[f\"scene_cluster_{total_k}\"],})\n",
    "#     this_cluster = umap_df[umap_df[\"cluster_id\"]==this_cluster_num]\n",
    "\n",
    "#     image_files = this_cluster[\"image_files\"].tolist()\n",
    "\n",
    "#     n_images = 54\n",
    "\n",
    "#     # Load images\n",
    "#     image_files_sample =random.sample(image_files, k=n_images)\n",
    "#     images = [Image.open(f) for f in image_files_sample]\n",
    "\n",
    "#     # Define grid size\n",
    "#     cols = 7  # number of columns in grid\n",
    "#     rows = ceil(n_images / cols)\n",
    "\n",
    "#     # Create figure\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     # Plot images\n",
    "#     for ax, img in zip(axes, images):\n",
    "#         ax.imshow(img)\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     # Turn off any extra axes\n",
    "#     for ax in axes[n_images:]:\n",
    "#         ax.axis('off')\n",
    "        \n",
    "#     fig.suptitle(this_cluster_num)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
