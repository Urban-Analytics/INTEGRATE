{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64213a11",
   "metadata": {},
   "source": [
    "## ProcessEmbeddings+FindMeanEmbeddingPerLSOA\n",
    "This script:\n",
    "- Loads the pickle file containing each sample point, the list of image files, the list of embeddings and the list of similarity scores\n",
    "- Converts it so that each image (and associated embedding/scores) is its own row\n",
    "- Removes some outlying images:\n",
    "    - This stage may not be necessary, but does effectively remove images of both inside of buildings and inside of cars.\n",
    "    - This is based on using UMAP to reduce the dimensionality of embeddings to 2, and then plotting in 2-dimensional space.\n",
    "    There are two very clearly separated clusters of points which when I looked at the images within them, were those inside the cars and inside the buildings\n",
    "- Saves the results for use in future scripts\n",
    "- Finds the mean embedding in each LSOA, and saves a csv file containing this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8cf3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import random\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f89e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"../../../../data/embeddings/\")\n",
    "lsoas_file = os.path.join(\"../../../../data/SpatialData/\", \"LSOAs_2021\", \"LSOA_2021_EW_BSC_V4.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a64fe",
   "metadata": {},
   "source": [
    "### Get spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8395946f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsoas =  gpd.read_file(lsoas_file)\n",
    "manc_lads = ['Manchester', 'Rochdale', 'Bolton', 'Bury', 'Wigan', 'Oldham',  'Trafford', 'Salford', 'Tameside', 'Stockport']\n",
    "manc_lads_pattern = '|'.join(manc_lads)\n",
    "gm_lsoa=lsoas[lsoas['LSOA21NM'].str.contains(manc_lads_pattern)]\n",
    "gm_lsoa = gm_lsoa.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2331d9",
   "metadata": {},
   "source": [
    "### Get embeddings (four per location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3b8511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_data_cache = data_dir + f\"embeddings/points_data_cache_with_CLIP_embeddings_and_scores_planninguseclasses.pkl\"\n",
    "with open(points_data_cache, \"rb\") as f:\n",
    "    point_records = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4899715",
   "metadata": {},
   "source": [
    "### Join image embeddings points to gentrification LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af05acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points after spatial join: 18897 / 18897 `(some points may lie outside the label polygons and were dropped)\n"
     ]
    }
   ],
   "source": [
    "point_coords = [Point(rec['longitude'], rec['latitude']) for rec in point_records]\n",
    "points_labels_gdf = gpd.GeoDataFrame(point_records, geometry=point_coords, crs=\"EPSG:4326\")\n",
    "\n",
    "# Perform spatial join to get gentrification label for each point\n",
    "points_labels_gdf = gpd.sjoin(points_labels_gdf, gm_lsoa, how='inner', predicate='within')\n",
    "\n",
    "# sjoin may add an index from the polygon ('index_right'); we can drop it\n",
    "if 'index_right' in points_labels_gdf.columns:\n",
    "    points_labels_gdf = points_labels_gdf.drop(columns=['index_right'])\n",
    "\n",
    "print(f\"Points after spatial join: {len(points_labels_gdf)} / {len(point_records)}\"\n",
    "      f\" `(some points may lie outside the label polygons and were dropped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63915949",
   "metadata": {},
   "source": [
    "# Expand dataframe so there is one row per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5c82ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row 9158: 3 embedding, 4 images\n",
      "Skipping row 18664: 3 embedding, 4 images\n",
      "Original rows: 18897, Expanded rows: 75580\n"
     ]
    }
   ],
   "source": [
    "expanded_rows = []\n",
    "\n",
    "for _, row in points_labels_gdf.iterrows():\n",
    "    embeddings = row['embedding']      # list of 4 embeddings\n",
    "    images = row['image_files']        # list of 4 image paths\n",
    "    cat_scores = row['category_scores']        # list of 4 image paths\n",
    "    \n",
    "    # Skip if lengths don't match\n",
    "    if len(embeddings) != len(images):\n",
    "        print(f\"Skipping row {row.name}: {len(embeddings)} embedding, {len(images)} images\")\n",
    "        continue\n",
    "\n",
    "    for score, emb, img in zip(cat_scores, embeddings, images):\n",
    "        new_row = row.to_dict()        # copy all other columns\n",
    "        new_row['embedding'] = emb     # single embedding\n",
    "        new_row['image_files'] = img    # single image\n",
    "        new_row['category_scores'] = score\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "# Create new DataFrame\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)\n",
    "print(f\"Original rows: {len(points_labels_gdf)}, Expanded rows: {len(expanded_gdf)}\")\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65b2f7",
   "metadata": {},
   "source": [
    "# Remove inside cars and inside buildings images\n",
    "This stage is potentially not necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c25d1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Example wrapper if you have a dataframe\n",
    "# embeddings = np.vstack(expanded_gdf[\"embedding\"].values)   # shape (N, 512)\n",
    "#              # string labels\n",
    "# reducer = umap.UMAP(\n",
    "#     n_neighbors=30, \n",
    "#     min_dist=0.1, \n",
    "#     metric='cosine',   # âœ” recommended for CLIP embeddings\n",
    "#     random_state=42)\n",
    "\n",
    "# emb_2d = reducer.fit_transform(embeddings)  # shape (N, 2)\n",
    "\n",
    "# expanded_gdf['umap_x'] = emb_2d[:, 0]\n",
    "# expanded_gdf['umap_y'] = emb_2d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826ea893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------\n",
    "# # 2. Define MULTIPLE bounding boxes\n",
    "# #    Format: (x_min, x_max, y_min, y_max)\n",
    "# # ---------------------------------------------------------\n",
    "# bounding_boxes = [(5.7, 6.3, 9.5, 10),     # Box 1\n",
    "#                   (2.3, 3.2, 8.5,9)]\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 3. Build mask for ANY point inside ANY box\n",
    "# # ---------------------------------------------------------\n",
    "# inside_any_box = np.zeros(len(expanded_gdf), dtype=bool)\n",
    "\n",
    "# for (x_min, x_max, y_min, y_max) in bounding_boxes:\n",
    "#     inside_this_box = (\n",
    "#         (expanded_gdf[\"umap_x\"] >= x_min) & (expanded_gdf[\"umap_x\"] <= x_max) &\n",
    "#         (expanded_gdf[\"umap_y\"] >= y_min) & (expanded_gdf[\"umap_y\"] <= y_max))\n",
    "#     inside_any_box |= inside_this_box      # combine masks\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 4. Remove all points inside any bounding box\n",
    "# # ---------------------------------------------------------\n",
    "# expanded_gdf_filtered = expanded_gdf[~inside_any_box].copy()\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # 5. Visual sanity check\n",
    "# # ---------------------------------------------------------\n",
    "# plt.figure(figsize=(4, 3))\n",
    "\n",
    "# # Points kept\n",
    "# plt.scatter(expanded_gdf_filtered[\"umap_x\"], expanded_gdf_filtered[\"umap_y\"], s=2, alpha=0.25, label=\"kept\")\n",
    "\n",
    "# # Points removed\n",
    "# plt.scatter(expanded_gdf.loc[inside_any_box, \"umap_x\"], expanded_gdf.loc[inside_any_box, \"umap_y\"], s=10, color=\"red\",\n",
    "#             label=\"removed\")\n",
    "\n",
    "# # Draw rectangles on the plot\n",
    "# ax = plt.gca()\n",
    "# for (x_min, x_max, y_min, y_max) in bounding_boxes:\n",
    "#     rect = plt.Rectangle((x_min, y_min),x_max - x_min,y_max - y_min,linewidth=2,edgecolor=\"black\", facecolor=\"none\")\n",
    "#     ax.add_patch(rect)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title(\"UMAP with Multiple Removed Bounding Boxes\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # (Optional) overwrite original:\n",
    "# expanded_gdf = expanded_gdf_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a2e63",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc89017",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_gdf.to_pickle(data_dir + f\"embeddings/one_row_per_image_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207deac5",
   "metadata": {},
   "source": [
    "### Find mean embedding per LSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ea95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['geometry', 'GlobalID', 'LSOA21NMW', 'BNG_E', 'BNG_N', 'LAT', 'LONG',  'LSOA21NM']:\n",
    "    del expanded_gdf[col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312304cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation functions\n",
    "def mean_embed(series):\n",
    "    return np.mean(np.stack(series.values), axis=0)\n",
    "\n",
    "# Aggregation functions\n",
    "def median_embed(series):\n",
    "    return np.median(np.stack(series.values), axis=0)\n",
    "\n",
    "emb_cat_mean = expanded_gdf.groupby(\"LSOA21CD\")[\"embedding\"].apply(mean_embed).reset_index()\n",
    "emb_cat_mean.rename(columns={\"embedding\": \"mean_embedding\"}, inplace=True)\n",
    "\n",
    "emb_cat_median = expanded_gdf.groupby(\"LSOA21CD\")[\"embedding\"].apply(median_embed).reset_index()\n",
    "emb_cat_median.rename(columns={\"embedding\": \"median_embedding\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3e3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cat_mean.to_pickle(\n",
    "    data_dir + \"per_lsoa_embedding_summaries/mean_embedding.pkl\")\n",
    "\n",
    "emb_cat_median.to_pickle(\n",
    "    data_dir + \"per_lsoa_embedding_summaries/median_embedding.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
