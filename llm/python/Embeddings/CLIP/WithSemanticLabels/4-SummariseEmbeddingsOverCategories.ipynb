{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44744914",
   "metadata": {},
   "source": [
    "## SummariseEmbeddingsOverCategories\n",
    "This script:\n",
    "- Reads in a pickle files which contains a dataframe with one row per sampled image. Each image is associated with a location (lat, lon), a link to the image_file, an embedding and category_scores\n",
    "- Assigns image to one category based on which has the highest score\n",
    "- Finds the percentage of images in each LSOA, within each of the categories\n",
    "- Finds the mean/min/max embedding within each category, within each LSOA\n",
    "- Saves a pickle file containing a dataframe containing this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d8cf3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import hdbscan \n",
    "from sklearn.ensemble import IsolationForest\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "import umap\n",
    "import random\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09f89e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"../../../../data/embeddings/\")\n",
    "lsoas_file = os.path.join(\"../../../../data/SpatialData/\", \"LSOAs_2021\", \"LSOA_2021_EW_BSC_V4.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3910c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Two options depending on which semantic categories are being used\n",
    "file_ending = 'userdefinedclasses' #'planninguseclasses' #userdefinedclasses\n",
    "headline_categories = categories_dict[file_ending]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a64fe",
   "metadata": {},
   "source": [
    "### Get spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8395946f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsoas =  gpd.read_file(lsoas_file)\n",
    "manc_lads = ['Manchester', 'Rochdale', 'Bolton', 'Bury', 'Wigan', 'Oldham',  'Trafford', 'Salford', 'Tameside', 'Stockport']\n",
    "manc_lads_pattern = '|'.join(manc_lads)\n",
    "gm_lsoa=lsoas[lsoas['LSOA21NM'].str.contains(manc_lads_pattern)]\n",
    "gm_lsoa = gm_lsoa.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2331d9",
   "metadata": {},
   "source": [
    "### Get embeddings (four per location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e3b8511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_data_cache = data_dir + f\"sample_points_cache/points_data_cache_with_CLIP_embeddings_and_scores_{file_ending}.pkl\"\n",
    "with open(points_data_cache, \"rb\") as f:\n",
    "    point_records = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4899715",
   "metadata": {},
   "source": [
    "### Join image embeddings points to gentrification LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5af05acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points after spatial join: 18897 / 18897 `(some points may lie outside the label polygons and were dropped)\n"
     ]
    }
   ],
   "source": [
    "point_coords = [Point(rec['longitude'], rec['latitude']) for rec in point_records]\n",
    "points_labels_gdf = gpd.GeoDataFrame(point_records, geometry=point_coords, crs=\"EPSG:4326\")\n",
    "\n",
    "# Perform spatial join to get gentrification label for each point\n",
    "points_labels_gdf = gpd.sjoin(points_labels_gdf, gm_lsoa, how='inner', predicate='within')\n",
    "# sjoin may add an index from the polygon ('index_right'); we can drop it\n",
    "if 'index_right' in points_labels_gdf.columns:\n",
    "    points_labels_gdf = points_labels_gdf.drop(columns=['index_right'])\n",
    "\n",
    "print(f\"Points after spatial join: {len(points_labels_gdf)} / {len(point_records)}\"\n",
    "      f\" `(some points may lie outside the label polygons and were dropped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6934142",
   "metadata": {},
   "source": [
    "# Find mean embedding at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12c9314f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "points_labels_gdf[\"mean_embedding\"] = points_labels_gdf[\"embedding\"].apply(\n",
    "    lambda emb_list: np.mean(np.stack(emb_list), axis=0)) \n",
    "# save\n",
    "# points_labels_gdf[['LSOA21CD', 'mean_embedding']].to_pickle(data_dir + \"embedding_summaries/mean_embeddings_per_location_CLIP.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63915949",
   "metadata": {},
   "source": [
    "# Expand dataframe so there is one row per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a5c82ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row 9158: 3 embedding, 4 images\n",
      "Skipping row 18664: 3 embedding, 4 images\n",
      "Original rows: 18897, Expanded rows: 75580\n"
     ]
    }
   ],
   "source": [
    "expanded_rows = []\n",
    "\n",
    "for _, row in points_labels_gdf.iterrows():\n",
    "    embeddings = row['embedding']      # list of 4 embeddings\n",
    "    images = row['image_files']        # list of 4 image paths\n",
    "    cat_scores = row['category_scores']        # list of 4 image paths\n",
    "    \n",
    "    # Skip if lengths don't match\n",
    "    if len(embeddings) != len(images):\n",
    "        print(f\"Skipping row {row.name}: {len(embeddings)} embedding, {len(images)} images\")\n",
    "        continue\n",
    "\n",
    "    for score, emb, img in zip(cat_scores, embeddings, images):\n",
    "        new_row = row.to_dict()        # copy all other columns\n",
    "        new_row['embedding'] = emb     # single embedding\n",
    "        new_row['image_files'] = img    # single image\n",
    "        new_row['category_scores'] = score\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "# Create new DataFrame\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)\n",
    "print(f\"Original rows: {len(points_labels_gdf)}, Expanded rows: {len(expanded_gdf)}\")\n",
    "expanded_gdf = pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735801ac",
   "metadata": {},
   "source": [
    "## Assign each image to one classification, based on highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "064c1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all images across all points\n",
    "all_image_paths = []\n",
    "all_scores = []\n",
    "\n",
    "for idx, rec in expanded_gdf.iterrows():\n",
    "    all_image_paths.extend(rec[\"image_files\"])\n",
    "    all_scores.append(rec[\"category_scores\"])\n",
    "\n",
    "# Convert list of arrays → single (N,9) array\n",
    "all_scores = np.vstack(all_scores)\n",
    "\n",
    "category_probs = np.array(all_scores)\n",
    "assigned_labels = category_probs.argmax(axis=1)\n",
    "assigned_names = [headline_categories[i] for i in assigned_labels]\n",
    "expanded_gdf['category'] = assigned_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fadaf",
   "metadata": {},
   "source": [
    "# Create a dataframe with % of images in each category, in each LSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c566f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_embeddings = np.stack(expanded_gdf['embedding'].values)\n",
    "df = expanded_gdf\n",
    "category_column = \"category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4018ba04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA21CD</th>\n",
       "      <th>total_images</th>\n",
       "      <th>count_car</th>\n",
       "      <th>count_cucumber</th>\n",
       "      <th>count_highway</th>\n",
       "      <th>count_industrial</th>\n",
       "      <th>count_office</th>\n",
       "      <th>count_park</th>\n",
       "      <th>count_residential_street</th>\n",
       "      <th>count_shops_and_cafes</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_car</th>\n",
       "      <th>pct_cucumber</th>\n",
       "      <th>pct_highway</th>\n",
       "      <th>pct_industrial</th>\n",
       "      <th>pct_office</th>\n",
       "      <th>pct_park</th>\n",
       "      <th>pct_residential_street</th>\n",
       "      <th>pct_shops_and_cafes</th>\n",
       "      <th>pct_single_house</th>\n",
       "      <th>pct_urban_street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01004766</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>9.375000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>35.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01004767</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.722222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>34.722222</td>\n",
       "      <td>30.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01004768</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>29.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01004769</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01004770</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA21CD  total_images  count_car  count_cucumber  count_highway  \\\n",
       "0  E01004766          64.0        3.0             0.0            0.0   \n",
       "1  E01004767          72.0        7.0             0.0            3.0   \n",
       "2  E01004768          44.0        1.0             0.0            0.0   \n",
       "3  E01004769          40.0        3.0             0.0            0.0   \n",
       "4  E01004770          40.0        0.0             0.0            0.0   \n",
       "\n",
       "   count_industrial  count_office  count_park  count_residential_street  \\\n",
       "0               1.0           0.0         4.0                       6.0   \n",
       "1               0.0           0.0         3.0                      10.0   \n",
       "2               0.0           0.0         5.0                       5.0   \n",
       "3               2.0           0.0         6.0                       6.0   \n",
       "4               1.0           0.0         0.0                       9.0   \n",
       "\n",
       "   count_shops_and_cafes  ...   pct_car  pct_cucumber  pct_highway  \\\n",
       "0                    1.0  ...  4.687500           0.0     0.000000   \n",
       "1                    2.0  ...  9.722222           0.0     4.166667   \n",
       "2                    0.0  ...  2.272727           0.0     0.000000   \n",
       "3                    0.0  ...  7.500000           0.0     0.000000   \n",
       "4                    0.0  ...  0.000000           0.0     0.000000   \n",
       "\n",
       "   pct_industrial  pct_office   pct_park  pct_residential_street  \\\n",
       "0          1.5625         0.0   6.250000                9.375000   \n",
       "1          0.0000         0.0   4.166667               13.888889   \n",
       "2          0.0000         0.0  11.363636               11.363636   \n",
       "3          5.0000         0.0  15.000000               15.000000   \n",
       "4          2.5000         0.0   0.000000               22.500000   \n",
       "\n",
       "   pct_shops_and_cafes  pct_single_house  pct_urban_street  \n",
       "0             1.562500         40.625000         35.937500  \n",
       "1             2.777778         34.722222         30.555556  \n",
       "2             0.000000         45.454545         29.545455  \n",
       "3             0.000000         35.000000         22.500000  \n",
       "4             0.000000         35.000000         40.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Count images per (LSOA, category) ---\n",
    "category_counts = (df.groupby([\"LSOA21CD\", category_column]).size().reset_index(name=\"count\"))\n",
    "\n",
    "# --- 2. Total images per LSOA ---\n",
    "total_counts = (df.groupby(\"LSOA21CD\").size().reset_index(name=\"total_images\"))\n",
    "\n",
    "# --- 3. Merge totals ---\n",
    "category_counts = category_counts.merge(total_counts, on=\"LSOA21CD\")\n",
    "\n",
    "# --- 4. Add percentage for each category ---\n",
    "category_counts[\"pct\"] = (category_counts[\"count\"] / category_counts[\"total_images\"] * 100)\n",
    "\n",
    "# --- 5. Wide table: counts in columns ---\n",
    "counts_wide = (category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"count\").fillna(0).add_prefix(\"count_\"))\n",
    "\n",
    "# --- 6. Wide table: percentages in columns ---\n",
    "pct_wide = (category_counts.pivot(index=\"LSOA21CD\", columns=category_column, values=\"pct\")\n",
    "        .fillna(0).add_prefix(\"pct_\"))\n",
    "\n",
    "# --- 7. Combine both + total images per LSOA ---\n",
    "lsoa_summary = (total_counts.set_index(\"LSOA21CD\").join([counts_wide, pct_wide]))\n",
    "\n",
    "# plt.hist(lsoa_summary['total_images'], bins=20)\n",
    "\n",
    "lsoa_summary = lsoa_summary.merge(gm_lsoa['LSOA21CD'],'right', on = \"LSOA21CD\")\n",
    "lsoa_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e13faf",
   "metadata": {},
   "source": [
    "# Spatial plot of percentage in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98364909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # merge with LSOA shapes\n",
    "# plot_gdf = gm_lsoa.merge(category_pct_wide, on=\"LSOA21CD\", how=\"left\").fillna(0)\n",
    "\n",
    "# # list of categories\n",
    "# category_names = category_pct_wide.columns.tolist()\n",
    "\n",
    "# # -------------------------\n",
    "# # 2. Create subplots\n",
    "# # -------------------------\n",
    "\n",
    "# n = len(category_names)\n",
    "# ncols = 3\n",
    "# nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 5*nrows))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for ax, category in zip(axs, category_names):\n",
    "#     plot_gdf.plot(column=category, ax=ax, legend=True, cmap=\"viridis\",\n",
    "#         edgecolor=\"black\",  linewidth=0.2, legend_kwds={\"shrink\": 0.5})\n",
    "#     ax.set_title(f\"{category} (%)\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # turn off any empty axes\n",
    "# for empty_ax in axs[len(category_names):]:\n",
    "#     empty_ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48673ab",
   "metadata": {},
   "source": [
    "# Find mean/median/max embedding in each LSOA, also by catgeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "433d59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation functions\n",
    "def mean_embed(series):\n",
    "    return np.mean(np.stack(series.values), axis=0)\n",
    "\n",
    "def max_embed(series):\n",
    "    return np.max(np.stack(series.values), axis=0)\n",
    "\n",
    "def median_embed(series):\n",
    "    return np.median(np.stack(series.values), axis=0)\n",
    "\n",
    "agg_funcs = {\"mean\": mean_embed, \"max\": max_embed, \"median\": median_embed}\n",
    "\n",
    "# List of categories\n",
    "categories = df[category_column].unique()\n",
    "\n",
    "# Initialize list to hold all DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "for agg_name, func in agg_funcs.items():\n",
    "    dfs = []\n",
    "    \n",
    "    # Per-category embeddings\n",
    "    for cat in categories:\n",
    "        df_cat = df[df[category_column] == cat]\n",
    "        emb_cat = df_cat.groupby(\"LSOA21CD\")[\"embedding\"].apply(func).reset_index()\n",
    "        emb_cat = emb_cat.rename(columns={\"embedding\": f\"{cat}_{agg_name}\"})\n",
    "        dfs.append(emb_cat)\n",
    "    \n",
    "    # Merge all categories\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), dfs)\n",
    "    \n",
    "    # Overall embedding (all images in LSOA)\n",
    "    overall = expanded_gdf.groupby(\"LSOA21CD\")[\"embedding\"].apply(func).reset_index()\n",
    "    overall = overall.rename(columns={\"embedding\": f\"overall_{agg_name}\"})\n",
    "    \n",
    "    merged = merged.merge(overall, on=\"LSOA21CD\", how=\"left\")\n",
    "    \n",
    "    all_dfs.append(merged)\n",
    "\n",
    "# Merge mean, max, median into a single DataFrame\n",
    "final_df = reduce(lambda left, right: pd.merge(left, right, on=\"LSOA21CD\", how=\"outer\"), all_dfs)\n",
    "\n",
    "# # Fill missing embeddings with zeros if needed\n",
    "# final_df = final_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a746d",
   "metadata": {},
   "source": [
    "# Create one dataframe with all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "491fc8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.merge(lsoa_summary, on = \"LSOA21CD\")\n",
    "final_df.to_pickle(data_dir + f\"embedding_summaries/big_summary_df_{file_ending}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
