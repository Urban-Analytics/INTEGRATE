---
title: "Sensitivity analysis-restaurant reviews (binary)"
author: "Yiyu Wang"
date: "September 2025"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document:
    keep_tex: true
    latex_engine: xelatex
subparagraph: true
urlcolor: blue
linkcolor: black
header-includes:
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{booktabs}
---

```{r setup, eval = T, echo = F, message=F, warning=F, results='hide'}
library(knitr)
library(kableExtra)
options(width=60)
opts_chunk$set(echo = TRUE, comment="", error=FALSE, 
               #cache.lazy = FALSE, 
               fig.align="center", message=FALSE, warning=FALSE, tidy = FALSE)
```

## LLM-based Analysis for Restaurant, Movie and Music Reviews
## 1.1 LLM Sensitivity analysis - restaurant reviews

```{r codeblock}
### Setup
library(tidyverse)
library(httr)
library(jsonlite)
library(ggplot2)
library(glue)
library(dplyr)
library(purrr)
library(readr)
library(stringr)
library(scales)
```

```{r, eval=FALSE}
## Load restaurant review data
restaurant_data <- read.csv("data/restuarant_review_binary.csv")
# head(restaurant_data)
# dim(restaurant_data)

# generate prompt with different batch_size
# 1) Dynamically generate the "task text" used in user message
generate_prompt <- function(batch_size) {
  glue(
    "You are an AI designed to assess sentiment in restaurant reviews.
    I will provide you with a batch of {batch_size} restaurant reviews. Your task is to analyze each review and determine whether the reviewer liked the restaurant (1) or did not like it (0).

    Specifically: Read each review closely and identify any words, phrases, or sentiments that indicate positive or negative sentiment about the restaurant experience.
    Consider:
    - Food quality and taste
    - Service quality
    - Atmosphere and ambiance
    - Value for money
    - Overall satisfaction

    Assign a score (0 or 1), where: 1 = The reviewer liked the restaurant; 0 = The reviewer did not like the restaurant.
    DO NOT explain any reasoning. Return exactly {batch_size} scores, with no extra text.
    You must return exactly {batch_size} binary scores (0 or 1), one per review, in a structured format.
    The output MUST be a JSON array of exactly {batch_size} numbers.
    If there are fewer or more than {batch_size} scores, correct the response before returning it.
    Example output: [1, 0, 1, ..., 0] (exactly {batch_size} numbers).
    Make sure the JSON array is correctly formatted before returning it."
  )
}

# 2) Build messages: strict rules in system; task + reviews in user
build_messages <- function(batch_reviews) {
  n <- nrow(batch_reviews)
  
  sys_msg <- glue(
    "You are an AI that classifies sentiment in restaurant reviews.
     Return ONLY a JSON array of 0/1 with exactly {n} integers.
     No reasoning, no explanations, no labels, no extra text, no trailing commas.
     The first character must be '[' and the last must be ']'."
  )
  
  user_msg <- paste0(
    generate_prompt(n), "\n\n",
    paste0(seq_along(batch_reviews$Review), ". ", batch_reviews$Review, collapse = "\n")
  )
  
  list(
    list(role = "system", content = sys_msg),
    list(role = "user",   content = user_msg)
  )
}

# 3) Robustly parse model outputs into a numeric vector of length n_expected
parse_scores <- function(raw_output, n_expected) {
  # If reply looks like it was cut before ']', gently try to complete it
  txt <- trimws(raw_output)
  if (is.character(txt) && startsWith(txt, "[") && !grepl("\\]$", txt) && nchar(txt) < 20000) {
    raw_output <- paste0(raw_output, "]")
  }
  
  # 1) Direct JSON parse
  parsed <- try(jsonlite::fromJSON(raw_output), silent = TRUE)
  if (!inherits(parsed, "try-error") && is.numeric(parsed)) {
    scores <- as.numeric(parsed)
  } else {
    scores <- NULL
  }
  
  # 2) If failed, extract the first [...] block and parse
  if (is.null(scores)) {
    m <- regexpr("\\[[^\\]]*\\]", raw_output, perl = TRUE)
    if (m[1] != -1) {
      candidate <- substr(raw_output, m[1], m[1] + attr(m, "match.length") - 1)
      parsed2 <- try(jsonlite::fromJSON(candidate), silent = TRUE)
      if (!inherits(parsed2, "try-error") && is.numeric(parsed2)) {
        scores <- as.numeric(parsed2)
      }
    }
  }
  
  # 3) If still failed, extract all 0/1 tokens and truncate to expected length
  if (is.null(scores)) {
    toks <- gregexpr("\\b[01]\\b", raw_output, perl = TRUE)
    if (toks[[1]][1] != -1) {
      vals <- as.numeric(regmatches(raw_output, toks)[[1]])
      if (length(vals) >= n_expected) {
        scores <- vals[seq_len(n_expected)]
      }
    }
  }
  
  # 4) Final validation (length & values in {0,1})
  if (!is.null(scores) &&
      length(scores) == n_expected &&
      all(scores %in% c(0, 1))) {
    return(scores)
  }
  
  # Fallback to all-NA
  return(rep(NA_real_, n_expected))
}

# 4) Split helper - split dataset into batches (cleaner)
split_batches <- function(data, batch_size) {
  split(data, ceiling(seq_len(nrow(data)) / batch_size))
}

# API configuration
url <- "https://api.together.xyz/v1/chat/completions"
api_key <- api_key <- Sys.getenv("TOGETHER_API_KEY")

# Batch-level execution function
run_batch <- function(batch_reviews, param_row, batch_index, log_file = LOG_FILE) {
  messages <- build_messages(batch_reviews)
  scores <- rep(NA_real_, nrow(batch_reviews))  # default fallback
  
  # Request body (no stop token; rely on robust parser)
  body_list <- list(
    model = "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    messages = messages,
    temperature = param_row$temperature,
    top_p = param_row$top_p,
    top_k = param_row$top_k,
    max_tokens = param_row$max_tokens,
    stream = FALSE
  )
  
  response <- httr::POST(
    url,
    httr::add_headers(Authorization = paste("Bearer", api_key), `Content-Type` = "application/json"),
    body = jsonlite::toJSON(body_list, auto_unbox = TRUE),
    encode = "json"
  )
  
  status <- httr::status_code(response)
  ok <- status == 200
  
  # Parse response content (even on error, to capture server message)
  result <- try(httr::content(response, as = "parsed", type = "application/json"), silent = TRUE)
  
  # Extract raw assistant text if present
  assistant_reply <- NA_character_
  if (!inherits(result, "try-error") &&
      !is.null(result$choices) &&
      length(result$choices) > 0 &&
      !is.null(result$choices[[1]]$message$content)) {
    assistant_reply <- stringr::str_trim(result$choices[[1]]$message$content)
  }
  
  # Log HTTP + raw output
  log_entry <- paste0(
    "\n--- BATCH ", batch_index, " ---\n",
    "HTTP STATUS: ", status, "\n",
    "PARAMS: ", paste(capture.output(print(param_row)), collapse = " "), "\n",
    "RESPONSE:\n", ifelse(is.na(assistant_reply), "<no assistant content>", assistant_reply), "\n"
  )
  write(log_entry, file = log_file, append = TRUE)
  
  # If HTTP OK and we have assistant content, try robust parsing
  if (ok && !is.na(assistant_reply)) {
    parsed_scores <- parse_scores(assistant_reply, nrow(batch_reviews))
    
    # Optional one-time retry with even stricter reminder if completely NA
    if (all(is.na(parsed_scores))) {
      messages_retry <- messages
      messages_retry[[1]]$content <- paste0(messages_retry[[1]]$content,
                                            "\nIMPORTANT: Output ONLY the JSON array. No other text.")
      body_list$messages <- messages_retry
      
      response2 <- httr::POST(
        url,
        httr::add_headers(Authorization = paste("Bearer", api_key), `Content-Type` = "application/json"),
        body = jsonlite::toJSON(body_list, auto_unbox = TRUE),
        encode = "json"
      )
      result2 <- try(httr::content(response2, as = "parsed", type = "application/json"), silent = TRUE)
      assistant_reply2 <- NA_character_
      if (!inherits(result2, "try-error") &&
          !is.null(result2$choices) &&
          length(result2$choices) > 0 &&
          !is.null(result2$choices[[1]]$message$content)) {
        assistant_reply2 <- stringr::str_trim(result2$choices[[1]]$message$content)
      }
      if (!is.na(assistant_reply2)) {
        parsed_scores <- parse_scores(assistant_reply2, nrow(batch_reviews))
        write(paste0("Retry used for batch ", batch_index, "\n"), file = log_file, append = TRUE)
      }
    }
    
    scores <- parsed_scores
  } else {
    # HTTP NOT OK: log error message returned by server if present
    err_text <- try(httr::content(response, as = "text", encoding = "UTF-8"), silent = TRUE)
    write(paste0("ERROR in batch ", batch_index, ": HTTP ", status, " | ", as.character(err_text), "\n"),
          file = log_file, append = TRUE)
  }
  
  tibble(
    Review = batch_reviews$Review,
    GroundTruth = batch_reviews$Liked,
    Prediction = scores,
    batch_index = batch_index,
    temperature = param_row$temperature,
    top_p = param_row$top_p,
    top_k = param_row$top_k,
    max_tokens = param_row$max_tokens,
    batch_size = nrow(batch_reviews)
  )
}

# Logging & results directories
LOG_FILE <- file.path("logs", paste0("restaurant_sensitivity_new_", format(Sys.time(), "%Y-%m-%d-%H%M%S"), ".log"))
dir.create("logs", showWarnings = FALSE)
dir.create("results", showWarnings = FALSE)  # ensure output dir exists

# Parameter combination runner with auto-saving
run_exp_chunk <- function(dataset, param_chunk, chunk_id = 1) {
  batch_counter <- 1
  
  for (i in 1:nrow(param_chunk)) {
    param_row <- param_chunk[i, ]
    param_id <- paste0("chunk", chunk_id, "_param", i)
    output_file <- glue("results/{param_id}.csv")
    
    # Skip if already processed (resumable)
    if (file.exists(output_file)) {
      cat(glue("Skipping {param_id} (already exists)\n"))
      next
    }
    
    batches <- split_batches(dataset, param_row$batch_size)
    cat(glue("\n[Chunk {chunk_id}] Running param set {i}/{nrow(param_chunk)}\n"))
    combo_results <- vector("list", length(batches))
    
    for (b in seq_along(batches)) {
      result <- run_batch(batches[[b]], param_row, batch_counter)
      combo_results[[b]] <- result
      batch_counter <- batch_counter + 1
    }
    
    # Save results for this parameter combination
    result_df <- bind_rows(combo_results)
    write_csv(result_df, output_file)
  }
}

# Run experiments
# Parameter grid (243 total combinations)
param_grid <- expand.grid(
  temperature = c(0.1, 0.2, 0.5),
  top_p = c(0.8, 0.9, 1.0),
  top_k = c(20, 50, 100),
  max_tokens = c(50, 100, 200),
  batch_size = c(5, 10, 20),
  stringsAsFactors = FALSE
)

# Split the grid into chunks (manageable groups, e.g., 20 combos per chunk)
param_chunks <- split(param_grid, ceiling(seq_len(nrow(param_grid)) / 20))

# Run each chunk (resumable; you can run a subset if desired)
for (i in seq_along(param_chunks)) {
  cat(glue("=== Running parameter chunk {i}/{length(param_chunks)} ===\n"))
  run_exp_chunk(restaurant_data, param_chunks[[i]], chunk_id = i)
}

# Merge all result CSVs into one final file
all_csvs <- list.files("results", pattern = "*.csv", full.names = TRUE)
all_results <- purrr::map_dfr(all_csvs, readr::read_csv, show_col_types = FALSE)
write.csv(all_results, "restaurant_tuning_all_results_2.csv", row.names = FALSE)

# # check NA prediction
# sum(is.na(all_results))
# colSums(is.na(all_results))
# sum(is.na(all_results$Prediction))

# Helper: safe division
safe_div <- function(a, b) {
  ifelse(b == 0, NA_real_, a / b)
}

# Compute metrics 
compute_metrics_from_vecs <- function(y_true, y_pred) {
  tryCatch({
    y_true <- as.numeric(y_true)
    y_pred <- as.numeric(y_pred)
    
    tp <- sum(y_pred == 1 & y_true == 1, na.rm = TRUE)
    tn <- sum(y_pred == 0 & y_true == 0, na.rm = TRUE)
    fp <- sum(y_pred == 1 & y_true == 0, na.rm = TRUE)
    fn <- sum(y_pred == 0 & y_true == 1, na.rm = TRUE)
    
    acc <- safe_div(tp + tn, tp + tn + fp + fn)
    prec_pos <- safe_div(tp, tp + fp)
    rec_pos  <- safe_div(tp, tp + fn)
    f1_pos   <- ifelse(is.na(prec_pos) | is.na(rec_pos) | (prec_pos + rec_pos) == 0,
                       NA_real_, 2 * prec_pos * rec_pos / (prec_pos + rec_pos))
    
    # negative class metrics
    prec_neg <- safe_div(tn, tn + fn)
    rec_neg  <- safe_div(tn, tn + fp)
    f1_neg   <- ifelse(is.na(prec_neg) | is.na(rec_neg) | (prec_neg + rec_neg) == 0,
                       NA_real_, 2 * prec_neg * rec_neg / (prec_neg + rec_neg))
    
    macro_f1 <- mean(c(f1_pos, f1_neg), na.rm = TRUE)
    specificity <- rec_neg
    bal_acc <- mean(c(rec_pos, specificity), na.rm = TRUE)
    
    # cast to numeric to avoid integer overflow
    denom <- sqrt(as.numeric(tp + fp) * as.numeric(tp + fn) *
                    as.numeric(tn + fp) * as.numeric(tn + fn))
    mcc <- ifelse(denom == 0, NA_real_, ((tp * tn) - (fp * fn)) / denom)
    
    missing_rate <- mean(is.na(y_pred))
    
    tibble(
      accuracy = acc,
      precision = prec_pos,
      recall = rec_pos,
      f1_pos = f1_pos,
      f1_neg = f1_neg,
      macro_f1 = macro_f1,
      specificity = specificity,
      balanced_accuracy = bal_acc,
      mcc = mcc,
      missing_rate = missing_rate
    )
  }, error = function(e) {
    # return NA if error occur
    tibble(
      accuracy = NA_real_,
      precision = NA_real_,
      recall = NA_real_,
      f1_pos = NA_real_,
      f1_neg = NA_real_,
      macro_f1 = NA_real_,
      specificity = NA_real_,
      balanced_accuracy = NA_real_,
      mcc = NA_real_,
      missing_rate = mean(is.na(y_pred))
    )
  })
}

# Apply to restaurant results
results_df <- read_csv("restaurant_tuning_all_results_2.csv")

metrics_df <- results_df %>%
  group_by(temperature, top_p, top_k, max_tokens, batch_size) %>%
  summarise(
    metrics = list(compute_metrics_from_vecs(GroundTruth, Prediction)),
    .groups = "drop"
  ) %>%
  tidyr::unnest_wider(metrics) %>%
  arrange(desc(macro_f1), desc(accuracy), desc(mcc))

write_csv(metrics_df, "restaurant_tuning_metrics.csv")
```

# Visualization 
### 1) Accuracy across batch size & temperature

```{r p1}
# load data
metrics_df <- read_csv("restaurant_tuning_metrics.csv")

# convert parameters to factors
metrics_df <- metrics_df %>%
  mutate(temperature = factor(temperature),
         top_p = factor(top_p),
         top_k = factor(top_k),
         max_tokens = factor(max_tokens),
         batch_size = factor(batch_size))

my_colors <- c("0.1" = "#4C72B0",   
               "0.2" = "#DD8452",   
               "0.5" = "#55A868") 

# p1 - accuracy vs batch size
p1 <- metrics_df %>%
  ggplot(aes(x = batch_size, y = accuracy, fill = temperature)) +
  geom_col(position = position_dodge(width = 0.8), na.rm = FALSE) +
  labs(title = "Accuracy across batch size & tempertaure",
       x = "Batch size",
       y = "Accuracy",
       fill = "Temperature") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_manual(values = my_colors, na.value = "grey70") +
  theme_bw()
p1
```

### 2) Macro F1 by batch size & top_p

```{r p2}
# p2 - macro f1 vs. batch size & top_p
top_p_labels <- c("0.8" = "top_p = 0.8",
                  "0.9" = "top_p = 0.9",
                  "1"   = "top_p = 1.0")

p2 <- metrics_df %>%
  ggplot(aes(x = batch_size, y = macro_f1, color = temperature, group = temperature)) +
  geom_smooth(method = "loess", se = TRUE, alpha = 0.2, linewidth = 1) +
  geom_point(size = 2) +
  facet_wrap(~ top_p, nrow = 1, labeller = labeller(top_p = top_p_labels)) +
  labs(title = "Macro F1 Score by Batch Size & top_p (Restaurant)",
       x = "Batch size",
       y = "Macro F1 score",
       color = "Temperature", 
       fill = "Temperature") +
  scale_color_manual(values = my_colors, na.value = "grey70") +
  scale_fill_manual(values = my_colors, na.value = "grey70") +
  theme_bw(base_size = 12)
p2
```

### 3) Accuracy Heatmap across parameter combinations

```{r p3a-plot, fig.width=12, fig.height=8}
# p3 - heatmap: accuravy vs (top_k, max_tokens, batch_size)
# facet lables
temp_labels <- c("0.1" = "temp. = 0.1",
                 "0.2" = "temp. = 0.2",
                 "0.5" = "temp. = 0.5")
# p3-A: batch size as facet
p3_a <- metrics_df %>%
  ggplot(aes(x = max_tokens, y = top_k, fill = accuracy)) +
  geom_tile(color = "white") +
  labs(title = "Heatmap of Accuracy (top_k * max_tokens) by batch_size (Restaurant)",
       x = "max_tokens", y = "top_k", fill = "Accuracy") +
  scale_fill_gradient(low = "#f0f9e8", high = "#0868ac", na.value = "grey70",
                      labels = number_format(accuracy = 0.001)) +
  facet_grid(batch_size ~ top_p + temperature,
             labeller = labeller(temperature = temp_labels,
                                 top_p = top_p_labels,
                                 batch_size = label_both)) +
  guides(fill = guide_colorbar(title.position = "top", barwidth = 2)) +
  theme_minimal(base_size = 10) +
  theme(strip.background = element_rect(fill = "#f3f3f3", color = NA),
        strip.text = element_text(face = "bold", size = 8),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x  = element_text(size = 12),
        axis.text.y  = element_text(size = 12))
print(p3_a)
```

### 4) Accuracy Heatmap across parameter combinations (faceted by max_tokens)

```{r p3b-plot, fig.width=12, fig.height=8}
# p3-B: max_tokens as facet; x = batch_size
p3_b <- metrics_df %>%
  ggplot(aes(x = batch_size, y = top_k, fill = accuracy)) +
  geom_tile(color = "white") +
  labs(title = "Heatmap of Accuracy (batch_size * top_k), faceted by max_tokens (Restaurant)",
       x = "Batch size", y = "top_k", fill = "Accuracy") +
  scale_fill_gradient(low = "#f0f9e8", high = "#0868ac", na.value = "grey70",
                      labels = number_format(accuracy = 0.001)) +
  facet_grid(top_p ~ temperature + max_tokens,
             labeller = labeller(temperature = temp_labels,
                                 top_p = top_p_labels,
                                 max_tokens = label_both)) +
  guides(fill = guide_colorbar(title.position = "top", barwidth = 2)) +
  theme_minimal(base_size = 10) +
  theme(strip.background = element_rect(fill = "#f3f3f3", color = NA),
        strip.text = element_text(face = "bold", size = 8),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x  = element_text(size = 12),
        axis.text.y  = element_text(size = 12))

print(p3_b)
```

### 5) Precision vs Recall

```{r p4}
# p4 - precision vs recall
prec_thr <- 0.85
recall_thr <- 0.88

outliers <- metrics_df %>%
  filter(precision < prec_thr | recall < recall_thr) %>%
  mutate(combo_id = paste0("temp=", temperature,
                           "_top_p=", top_p,
                           "_top_k=", top_k,
                           "_max_tokens=", max_tokens,
                           "_batch=", batch_size))

p4 <- metrics_df %>%
  ggplot(aes(x = precision, y = recall,
             color = temperature, shape = batch_size)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_vline(xintercept = prec_thr, linetype = "dashed", color = "red", size = 0.7) +
  geom_hline(yintercept = recall_thr, linetype = "dashed", color = "red", size = 0.7) +
  geom_point(data = outliers, aes(x = precision, y = recall), 
             color = "black", fill = "yellow", size = 4, shape = 21, stroke = 1.2) +
  ggrepel::geom_text_repel(data = outliers, aes(x = precision, y = recall, label = combo_id),
                           size = 3, color = "black", max.overlaps = 10) +
  labs(title = "Precision vs Recall across parameter settings (Restaurant)",
       x = "Precision", y = "Recall",
       color = "Temperature", shape = "Batch Size") +
  theme_bw(base_size = 12)
p4
```

### 6) Balanced Accuracy vs MCC

```{r p5}
# p5 - Balanced Accuracy vs MCC
p5 <- metrics_df %>%
  ggplot(aes(x = balanced_accuracy, y = mcc,
             color = top_p)) +
  geom_point(size = 3, alpha = 0.8) +
  labs(title = "Balanced Accuracy vs MCC (Restaurant)",
       x = "Balanced Accuracy", y = "MCC",
       color = "top_p") +
  theme_bw(base_size = 12)
p5
```

### 7) Average missing rate vs batch size

```{r p6}
# p6 - Average Missing Rate vs Batch Size
p6 <- metrics_df %>%
  group_by(batch_size) %>%
  summarise(avg_missing = mean(missing_rate, na.rm = TRUE)) %>%
  ggplot(aes(x = batch_size, y = avg_missing, fill = batch_size)) +
  geom_col() +
  labs(title = "Average Missing Rate by Batch Size (Restaurant dataset)",
       x = "Batch size", y = "Avg. Missing Rate") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_brewer(palette = "Set2", na.value = "grey70") +
  theme_bw(base_size = 12)
p6
```

### 8) Failure rate heatmap

```{r p7, fig.width=12, fig.height=8}
# p7 - Failure Rate Heatmap
p7 <- metrics_df %>%
  ggplot(aes(x = max_tokens, y = top_k, fill = missing_rate)) +
  geom_tile(color = "white") +
  labs(title = "Failure Rate Heatmap across parameter combinations (Restaurant)",
       x = "max_tokens", y = "top_k", fill = "Missing Rate") +
  scale_fill_gradient(low = "#f0f9e8", high = "#d73027",
                      na.value = "grey70",
                      labels = percent_format(accuracy = 1)) +
  facet_grid(batch_size ~ temperature + top_p,
             labeller = labeller(
               temperature = label_both,
               top_p = label_both,
               batch_size = label_both)) +
  theme_minimal(base_size = 10) +
  theme(strip.background = element_rect(fill = "#f3f3f3", color = NA),
        strip.text = element_text(face = "bold", size = 8),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x  = element_text(size = 12),
        axis.text.y  = element_text(size = 12))
p7
```


