{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6e064c-feb0-4b03-bb6d-98b98ea218b1",
   "metadata": {},
   "source": [
    "# LLM Experiments\n",
    "\n",
    "Early experiments with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289af38-0fd0-4823-8189-3e0b1ab90aba",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "e4b1f357-001e-4fc1-bd1c-2061240de22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:48:53.833028Z",
     "start_time": "2024-10-14T14:48:53.179071Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from together import Together\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "2fedff62-cb63-42ba-962d-38f7430c5ebc",
   "metadata": {},
   "source": [
    "## Get test data\n",
    "\n",
    "Download the Kaggle Sentiment140 dataset (a load of tweets with sentiment; useful for experimenting)."
   ]
  },
  {
   "cell_type": "code",
   "id": "87b18521-5e3e-4cf7-9950-ab8321f0e8ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:48:55.656943Z",
     "start_time": "2024-10-14T14:48:53.841398Z"
    }
   },
   "source": [
    "data_dir = '../data/tweet_data'\n",
    "dataset = 'kazanova/sentiment140'\n",
    "\n",
    "# Function to download dataset if not already downloaded\n",
    "def download_kaggle_dataset(dataset, data_dir):\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # Check if dataset already exists\n",
    "    dataset_files = os.listdir(data_dir)\n",
    "    if not dataset_files:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_download_files(dataset, path=data_dir, unzip=True)\n",
    "        print(\"Dataset downloaded and extracted.\")\n",
    "    else:\n",
    "        print(\"Dataset already exists in the directory.\")\n",
    "\n",
    "# Run the function to download the dataset\n",
    "download_kaggle_dataset(dataset, data_dir)\n",
    "\n",
    "tweets_df = pd.read_csv(os.path.join(data_dir, 'training.1600000.processed.noemoticon.csv'),\n",
    "                        header=None,\n",
    "                        names=[\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"],\n",
    "                        dtype={\"polarity\": int, \"id\": int, \"date\": str, \"query\": str, \"user\": str, \"text\": str},\n",
    "                        encoding='latin1')\n",
    "\n",
    "tweets_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists in the directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         polarity          id                          date     query  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...           ...         ...                           ...       ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "47c5b212a4c05d4",
   "metadata": {},
   "source": "## Example code to access Together.AI API. "
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Get my API key (it's in a file)\n",
    "with open('together.ai_key.txt', 'r') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",\n",
    "    #model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "\n",
    "    messages=[\n",
    "        {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Classify the sentiment (positive, negative, or neutral) of the following text. Reply with one word.\"\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Played pub for the first time in a long time and loved it. Will post clips tonight!\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Played pub for the first time in a long time and loved it. Will post clips tonight!\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"\\\"Rock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it/RMTrgF \"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \",WE FINISHED BORDERLANDS 3 UPDATE YAS! Thank you for hanging out guys! It was fun. I will try to stream and even if not I might so some IRL streams while awayu. We shall go. Thank you so much for the raids @mompou_mumpow @MegaMagwitch and Hope.\\n\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Nvidia did delay by 3070 2 weeks.\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \",Nvidia Gives Positive Forecasts Despite Coronavirus Hit  . . cdrinfo.com/d7/content/nviâ€¦ https://t.co/utMxGW1CIf\\n\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"@BlizzardCSEU_EN... would you play wow classic with the @NVIDIAGFN service? I have sent an email where it hasn't been responded to. Nvidia say that wow classic and wow BFA will work at the price but I'm hearing and propels<unk> being cut. Is that still your standard?\\n\"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "        {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"I absolutely cannot stand winning all the time :-) \"\n",
    "                        }\n",
    "                ]\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "    truncate=130560,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    x=1\n",
    "  #print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)"
   ],
   "id": "b32f9fb59737775b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This loops over tweets individually and asks a llama more to clasify them",
   "id": "d18bf342b662e565"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:19:01.370952Z",
     "start_time": "2024-10-14T15:18:26.937766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the Together library\n",
    "from together import Together\n",
    "\n",
    "# Get the API key from a file\n",
    "with open('together.ai_key.txt', 'r') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "# List of tweets to classify\n",
    "tweets = [\n",
    "    \"Played pub for the first time in a long time and loved it. Will post clips tonight!\",\n",
    "    \"I hate when it rains all day.\",\n",
    "    \"It's an average day, nothing special happening.\",\n",
    "    # Add more tweets as needed\n",
    "]\n",
    "\n",
    "# Loop through each tweet and classify its sentiment\n",
    "for tweet in tweets:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",\n",
    "        # model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Classify the sentiment (positive, negative, or neutral) of the following text. Reply with one word.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": tweet\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=5,\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "        truncate=130560,\n",
    "        stream=False  # Set stream to False to get the full response\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's reply\n",
    "    sentiment = response.choices[0].message.content.strip()\n",
    "\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print()"
   ],
   "id": "ffbc8511acb6b40c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Played pub for the first time in a long time and loved it. Will post clips tonight!\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: I hate when it rains all day.\n",
      "Sentiment: Negative\n",
      "\n",
      "Tweet: It's an average day, nothing special happening.\n",
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This does them in batches (not _tested_)",
   "id": "f97ee1e9221e2aa9"
  },
  {
   "cell_type": "code",
   "id": "c51879a531b03a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:25:48.215433Z",
     "start_time": "2024-10-14T15:25:47.357892Z"
    }
   },
   "source": [
    "# Import the Together library\n",
    "from together import Together\n",
    "\n",
    "# Get the API key from a file\n",
    "with open('together.ai_key.txt', 'r') as f:\n",
    "    api_key = f.readline().strip()\n",
    "\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "# List of tweets to classify\n",
    "tweets = [\n",
    "    \"Played pub for the first time in a long time and loved it. Will post clips tonight!\",\n",
    "    \"I hate when it rains all day.\",\n",
    "    \"It's an average day, nothing special happening.\",\n",
    "    # Add more tweets as needed\n",
    "]\n",
    "\n",
    "# Construct the prompt by numbering each tweet\n",
    "tweet_list = \"\\n\".join([f\"{idx+1}. {tweet}\" for idx, tweet in enumerate(tweets)])\n",
    "\n",
    "# Create the system prompt\n",
    "system_prompt = (\n",
    "    \"Classify the sentiment (positive, negative, or neutral) of each of the following texts. \"\n",
    "    \"Provide your answer in the format '1. Sentiment', '2. Sentiment', etc.\\n\\n\"\n",
    "    f\"{tweet_list}\"\n",
    ")\n",
    "\n",
    "# Prepare the messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "    truncate=130560,\n",
    "    stream=False  # Set stream to False to get the full response\n",
    ")\n",
    "\n",
    "# Extract the assistant's reply\n",
    "assistant_reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Print the assistant's reply\n",
    "print(\"Assistant's Reply:\")\n",
    "print(assistant_reply)\n",
    "\n",
    "# Parse the assistant's reply to map sentiments to tweets\n",
    "import re\n",
    "\n",
    "# Create a dictionary to hold the sentiments\n",
    "sentiments = {}\n",
    "\n",
    "# Use regular expressions to extract the sentiments\n",
    "matches = re.findall(r\"(\\d+)\\.\\s*(Positive|Negative|Neutral)\", assistant_reply, re.IGNORECASE)\n",
    "\n",
    "for match in matches:\n",
    "    idx, sentiment = match\n",
    "    sentiments[int(idx)-1] = sentiment.capitalize()\n",
    "\n",
    "# Print the results\n",
    "for idx, tweet in enumerate(tweets):\n",
    "    sentiment = sentiments.get(idx, \"Not Classified\")\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant's Reply:\n",
      "Here are the sentiment classifications:\n",
      "\n",
      "1. Positive\n",
      "2. Negative\n",
      "3. Neutral\n",
      "Tweet: Played pub for the first time in a long time and loved it. Will post clips tonight!\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: I hate when it rains all day.\n",
      "Sentiment: Negative\n",
      "\n",
      "Tweet: It's an average day, nothing special happening.\n",
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abb8d4e87687fd0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
